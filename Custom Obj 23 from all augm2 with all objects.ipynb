{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('facies_vectors_0.csv')\n",
    "feature_names = ['GR_diff_up', 'ILD_log10_diff_up', 'DeltaPHI_diff_up', 'PHIND_diff_up', 'PE_diff_up', 'NM_M_diff_up', 'RELPOS_diff_up','GR_diff_down', 'ILD_log10_diff_down', 'DeltaPHI_diff_down', 'PHIND_diff_down', 'PE_diff_down', 'NM_M_diff_down', 'RELPOS_diff_down','GR', 'ILD_log10', 'DeltaPHI', 'PHIND', 'PE', 'NM_M', 'RELPOS']\n",
    "facies_names = ['SS', 'CSiS', 'FSiS', 'SiSh', 'MS', 'WS', 'D', 'PS', 'BS']\n",
    "facies_colors = ['#F4D03F', '#F5B041','#DC7633','#6E2C00', '#1B4F72','#2E86C1', '#AED6F1', '#A569BD', '#196F3D']\n",
    "data = data.fillna(data['PE'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_diff(row, well):\n",
    "    if len(prev_depth_features[well]) == 0:\n",
    "        prev_depth_features[well] = row.values[4:]\n",
    "        return\n",
    "    diff = row.values[4:] - prev_depth_features[well]\n",
    "    prev_depth_features[well] = row.values[4:]\n",
    "    return diff\n",
    "data_well = dict()\n",
    "data_well_inverse = dict()\n",
    "prev_depth_features = dict()\n",
    "new_data = pd.DataFrame()\n",
    "prev_class= dict()\n",
    "data_save = pd.DataFrame()\n",
    "for well in set(data['Well Name']):\n",
    "    prev_depth_features[well] = []\n",
    "    prev_class[well] = []\n",
    "    data_well[well] = data[data['Well Name'] == well]\n",
    "    data_well[well] = data_well[well].sort_values(by=['Depth'])\n",
    "    data_save = data_well[well].iloc[::-1]\n",
    "    data_well[well]['diff_up'] = data_well[well].apply(lambda row: find_diff(row, well), axis=1)\n",
    "    prev_depth_features[well] = []\n",
    "    prev_class[well] = []\n",
    "    data_save = data_save.apply(lambda row: find_diff(row, well), axis=1)\n",
    "    data_well[well]['diff_down'] = data_save.iloc[::-1]\n",
    "    data_well[well] = data_well[well].dropna()\n",
    "    data_well[well]['GR_diff_up'] = data_well[well].apply(lambda row: row['diff_up'][0], axis=1)\n",
    "    data_well[well]['ILD_log10_diff_up'] = data_well[well].apply(lambda row: row['diff_up'][1], axis=1)\n",
    "    data_well[well]['DeltaPHI_diff_up'] = data_well[well].apply(lambda row: row['diff_up'][2], axis=1)\n",
    "    data_well[well]['PHIND_diff_up'] = data_well[well].apply(lambda row: row['diff_up'][3], axis=1)\n",
    "    data_well[well]['PE_diff_up'] = data_well[well].apply(lambda row: row['diff_up'][4], axis=1)\n",
    "    data_well[well]['NM_M_diff_up'] = data_well[well].apply(lambda row: row['diff_up'][5], axis=1)\n",
    "    data_well[well]['RELPOS_diff_up'] = data_well[well].apply(lambda row: row['diff_up'][6], axis=1)\n",
    "    data_well[well]['GR_diff_down'] = data_well[well].apply(lambda row: row['diff_down'][0], axis=1)\n",
    "    data_well[well]['ILD_log10_diff_down'] = data_well[well].apply(lambda row: row['diff_down'][1], axis=1)\n",
    "    data_well[well]['DeltaPHI_diff_down'] = data_well[well].apply(lambda row: row['diff_down'][2], axis=1)\n",
    "    data_well[well]['PHIND_diff_down'] = data_well[well].apply(lambda row: row['diff_down'][3], axis=1)\n",
    "    data_well[well]['PE_diff_down'] = data_well[well].apply(lambda row: row['diff_down'][4], axis=1)\n",
    "    data_well[well]['NM_M_diff_down'] = data_well[well].apply(lambda row: row['diff_down'][5], axis=1)\n",
    "    data_well[well]['RELPOS_diff_down'] = data_well[well].apply(lambda row: row['diff_down'][6], axis=1)\n",
    "    new_data = pd.concat([new_data, data_well[well]])\n",
    "    new_data = new_data.drop(['diff_up'], axis=1)\n",
    "    new_data = new_data.drop(['diff_down'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_23(x):\n",
    "    if (x == 2):\n",
    "        return 0\n",
    "    if (x == 3):\n",
    "        return 1\n",
    "    return x\n",
    "new_data_2 = new_data[new_data['Facies'] == 2]\n",
    "new_data_3 = new_data[new_data['Facies'] == 3]\n",
    "new_data_23 = pd.concat([new_data_2, new_data_3])\n",
    "new_data_23['Facies'] = new_data_23.apply(lambda row: change_23(row['Facies']), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_features_window(X, N_neig):\n",
    "    N_row = X.shape[0]\n",
    "    N_feat = X.shape[1]\n",
    "    X = np.vstack((np.zeros((N_neig, N_feat)),np.zeros((N_neig, N_feat)), X, np.zeros((N_neig, N_feat)),np.zeros((N_neig, N_feat))))\n",
    "    X_aug = np.zeros((N_row, N_feat*(4*N_neig+1)))\n",
    "    for r in np.arange(N_row) + N_neig:\n",
    "        this_row = []\n",
    "        for c in np.arange(-N_neig,N_neig+1):\n",
    "            this_row = np.hstack((this_row, X[r+c]))\n",
    "            if c != 0:\n",
    "                this_row = np.hstack((this_row, (X[r] + X[r+c])/2))\n",
    "        #print(len(this_row))\n",
    "        X_aug[r-N_neig] = this_row\n",
    "\n",
    "    return X_aug\n",
    "\n",
    "def augment_features_gradient(X, depth):\n",
    "    d_diff = np.diff(depth).reshape((-1, 1))\n",
    "    d_diff[d_diff==0] = 0.001\n",
    "    X_diff = np.diff(X, axis=0)\n",
    "    X_grad = X_diff / d_diff\n",
    "    X_grad = np.concatenate((X_grad, np.zeros((1, X_grad.shape[1]))))\n",
    "    \n",
    "    return X_grad\n",
    "\n",
    "def augment_features(X, well, depth, N_neig=1):\n",
    "    X_aug = np.zeros((X.shape[0], X.shape[1]*(4*N_neig+1)))\n",
    "    for w in np.unique(well):\n",
    "        w_idx = np.where(well == w)[0]\n",
    "        X_aug_win = augment_features_window(X[w_idx, :], N_neig)\n",
    "        #print(X_aug_win)\n",
    "        #X_aug_grad = augment_features_gradient(X[w_idx, :], depth[w_idx])\n",
    "        #print(X_aug_grad)\n",
    "        X_aug[w_idx, :] = X_aug_win\n",
    "        #X_aug[w_idx, :] = np.concatenate((X_aug_win, X_aug_grad), axis=1)\n",
    "        \n",
    "    return X_aug\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start running example to used customized objective function\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import math\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "print('start running example to used customized objective function')\n",
    "\n",
    "params = {'max_depth': 2, 'eta': 0.1, 'silent': 1,\n",
    "          'objective': 'multi:softprob', 'num_class': 2}\n",
    "\n",
    "num_round = 2\n",
    "def my_softmax(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    labels_hot = OneHotEncoder(sparse=False, n_values=2).fit_transform(labels.reshape(-1, 1))\n",
    "    grad = preds - labels_hot\n",
    "    hess = preds * (1.0-preds)\n",
    "\n",
    "    return grad.flatten(), hess.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_of_outlier(y_res):\n",
    "    outliers = 0\n",
    "    if y_res[0] != y_res[1]:\n",
    "        outliers += 1\n",
    "    if y_res[-1] != y_res[-2]:\n",
    "        outliers += 1\n",
    "    for index in range(1,len(y_res)-1):\n",
    "        if ((y_res[index] != y_res[index-1]) and (y_res[index] != y_res[index+1])):\n",
    "            outliers += 1\n",
    "    return outliers/len(y_res)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KIMZEY A\n",
      "437   159\n",
      "0.7610062893081762\n",
      "Score on train  0.9465550547327752\n",
      "Outliers test 0.006289308176100629\n",
      "Outliers res 0.018867924528301886\n",
      "ALEXANDER D\n",
      "464   207\n",
      "0.8260869565217391\n",
      "Score on train  0.9401993355481728\n",
      "Outliers test 0.00966183574879227\n",
      "Outliers res 0.014492753623188406\n",
      "CROSS H CATTLE\n",
      "499   188\n",
      "0.6542553191489362\n",
      "Score on train  0.9416010498687664\n",
      "Outliers test 0.031914893617021274\n",
      "Outliers res 0.026595744680851064\n",
      "SHANKLE\n",
      "447   205\n",
      "0.6536585365853659\n",
      "Score on train  0.9429329794293297\n",
      "Outliers test 0.0\n",
      "Outliers res 0.08780487804878048\n",
      "SHRIMPLIN\n",
      "469   240\n",
      "0.7541666666666665\n",
      "Score on train  0.9456521739130435\n",
      "Outliers test 0.0\n",
      "Outliers res 0.0375\n",
      "LUKE G U\n",
      "459   245\n",
      "0.746938775510204\n",
      "Score on train  0.9447852760736196\n",
      "Outliers test 0.004081632653061225\n",
      "Outliers res 0.02857142857142857\n",
      "NOLAN\n",
      "413   185\n",
      "0.8000000000000002\n",
      "Score on train  0.9377865094957433\n",
      "Outliers test 0.021621621621621623\n",
      "Outliers res 0.043243243243243246\n",
      "CHURCHMAN BIBLE\n",
      "402   106\n",
      "0.6509433962264151\n",
      "Score on train  0.9383561643835615\n",
      "Outliers test 0.009433962264150943\n",
      "Outliers res 0.04716981132075472\n",
      "NEWBY\n",
      "461   177\n",
      "0.672316384180791\n",
      "Score on train  0.9478827361563518\n",
      "Outliers test 0.01694915254237288\n",
      "Outliers res 0.02824858757062147\n",
      "well, boosting of trees,  0.7243747026831437\n"
     ]
    }
   ],
   "source": [
    "import numpy.random as random\n",
    "test = dict()\n",
    "train = dict()\n",
    "acc = 0\n",
    "wells = set(new_data_23['Well Name'])\n",
    "for well in wells:\n",
    "# well = 'SHRIMPLIN'\n",
    "    if (well == \"RECRUIT F9\"):\n",
    "        continue\n",
    "    print(well)\n",
    "    test[well] = new_data[new_data['Well Name'] == well]\n",
    "    train[well] = new_data[new_data['Well Name'] != well]\n",
    "    X_train = train[well][feature_names].values \n",
    "    y_train = train[well]['Facies'].values \n",
    "    X_test = test[well][feature_names].values \n",
    "    y_test = test[well]['Facies'].values \n",
    "    well_train = train[well]['Well Name'].values\n",
    "    well_test = test[well]['Well Name'].values\n",
    "    depth_train = train[well]['Depth'].values\n",
    "    depth_test = test[well]['Depth'].values    \n",
    "\n",
    "    X_aug_train = augment_features(X_train,well_train,depth_train)\n",
    "    X_aug_test = augment_features(X_test,well_test,depth_test)\n",
    "\n",
    "    robust = preprocessing.RobustScaler(quantile_range=(25.0, 75.0)).fit(X_aug_train)\n",
    "    X_train_robust = robust.transform(X_aug_train)\n",
    "    X_test_robust = robust.transform(X_aug_test)\n",
    "\n",
    "    scaler = StandardScaler().fit(X_train_robust)\n",
    "    X_train_robust_norm = scaler.transform(X_train_robust)\n",
    "    X_test_robust_norm = scaler.transform(X_test_robust)\n",
    "    \n",
    "    y_train23 = []\n",
    "    X_train23 = []\n",
    "    y_test23 = []\n",
    "    X_test23 = []\n",
    "    for index in range(len(y_train)):\n",
    "        if ((y_train[index] == 2) or (y_train[index] == 3)):\n",
    "            y_train23.append(y_train[index] - 2)\n",
    "            X_train23.append(X_train_robust_norm[index])\n",
    "    for index in range(len(y_test)):\n",
    "        if ((y_test[index] == 2) or (y_test[index] == 3)):\n",
    "            y_test23.append(y_test[index] - 2)\n",
    "            X_test23.append(X_test_robust_norm[index])\n",
    "    dtrain = xgb.DMatrix(np.array(X_train23), label=np.array(y_train23))\n",
    "    dtest = xgb.DMatrix(np.array(X_test23), label=np.array(y_test23))\n",
    "    watchlist = [(dtest, 'eval'), (dtrain, 'train')]\n",
    "    model = xgb.Booster(params, [dtrain])\n",
    "    for _ in range(150):\n",
    "        pred = model.predict(dtrain)\n",
    "        g, h = my_softmax(pred, dtrain)\n",
    "        model.boost(dtrain, g, h)\n",
    "    yhat = model.predict(dtest)\n",
    "    yhat_labels = np.argmax(yhat, axis=1)\n",
    "\n",
    "    yhat_train = model.predict(dtrain)\n",
    "    yhat_labels_train = np.argmax(yhat_train, axis=1)\n",
    "    print(len(y_test), \" \", len(yhat_labels))\n",
    "    acc += f1_score(y_test23, yhat_labels, average='micro')\n",
    "    print(f1_score(y_test23, yhat_labels, average='micro'))\n",
    "    print(\"Score on train \", f1_score(y_train23, yhat_labels_train , average='micro'))\n",
    "    print(\"Outliers test\", number_of_outlier(y_test23))\n",
    "    print(\"Outliers res\", number_of_outlier(yhat_labels))\n",
    "print('well, boosting of trees, ', acc/9)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
