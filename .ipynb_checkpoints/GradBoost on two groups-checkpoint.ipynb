{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('facies_vectors_0.csv')\n",
    "feature_names = ['GR', 'ILD_log10', 'DeltaPHI', 'PHIND', 'PE', 'NM_M', 'RELPOS','GR_diff_up', 'ILD_log10_diff_up', 'DeltaPHI_diff_up', 'PHIND_diff_up', 'PE_diff_up', 'NM_M_diff_up', 'RELPOS_diff_up']\n",
    "facies_names = ['SS', 'CSiS', 'FSiS', 'SiSh', 'MS', 'WS', 'D', 'PS', 'BS']\n",
    "facies_colors = ['#F4D03F', '#F5B041','#DC7633','#6E2C00', '#1B4F72','#2E86C1', '#AED6F1', '#A569BD', '#196F3D']\n",
    "data = data.fillna(data['PE'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_diff(row, well):\n",
    "    if len(prev_depth_features[well]) == 0:\n",
    "        prev_depth_features[well] = row.values[4:]\n",
    "        return\n",
    "    diff = row.values[4:] - prev_depth_features[well]\n",
    "    prev_depth_features[well] = row.values[4:]\n",
    "    return diff\n",
    "data_well = dict()\n",
    "data_well_inverse = dict()\n",
    "prev_depth_features = dict()\n",
    "new_data = pd.DataFrame()\n",
    "prev_class= dict()\n",
    "data_save = pd.DataFrame()\n",
    "for well in set(data['Well Name']):\n",
    "    prev_depth_features[well] = []\n",
    "    prev_class[well] = []\n",
    "    data_well[well] = data[data['Well Name'] == well]\n",
    "    data_well[well] = data_well[well].sort_values(by=['Depth'])\n",
    "    data_save = data_well[well].iloc[::-1]\n",
    "    data_well[well]['diff_up'] = data_well[well].apply(lambda row: find_diff(row, well), axis=1)\n",
    "    prev_depth_features[well] = []\n",
    "    prev_class[well] = []\n",
    "\n",
    "    data_well[well] = data_well[well].dropna()\n",
    "    data_well[well]['GR_diff_up'] = data_well[well].apply(lambda row: row['diff_up'][0], axis=1)\n",
    "    data_well[well]['ILD_log10_diff_up'] = data_well[well].apply(lambda row: row['diff_up'][1], axis=1)\n",
    "    data_well[well]['DeltaPHI_diff_up'] = data_well[well].apply(lambda row: row['diff_up'][2], axis=1)\n",
    "    data_well[well]['PHIND_diff_up'] = data_well[well].apply(lambda row: row['diff_up'][3], axis=1)\n",
    "    data_well[well]['PE_diff_up'] = data_well[well].apply(lambda row: row['diff_up'][4], axis=1)\n",
    "    data_well[well]['NM_M_diff_up'] = data_well[well].apply(lambda row: row['diff_up'][5], axis=1)\n",
    "    data_well[well]['RELPOS_diff_up'] = data_well[well].apply(lambda row: row['diff_up'][6], axis=1)\n",
    "\n",
    "    new_data = pd.concat([new_data, data_well[well]])\n",
    "    new_data = new_data.drop(['diff_up'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_features_window(X, N_neig):\n",
    "    N_row = X.shape[0]\n",
    "    N_feat = X.shape[1]\n",
    "    X = np.vstack((np.zeros((N_neig, N_feat)),np.zeros((N_neig, N_feat)), X, np.zeros((N_neig, N_feat)),np.zeros((N_neig, N_feat))))\n",
    "    X_aug = np.zeros((N_row, N_feat*(4*N_neig+1)))\n",
    "    for r in np.arange(N_row) + N_neig:\n",
    "        this_row = []\n",
    "        for c in np.arange(-N_neig,N_neig+1):\n",
    "            this_row = np.hstack((this_row, X[r+c]))\n",
    "            if c != 0:\n",
    "                this_row = np.hstack((this_row, (X[r] + X[r+c])/2))\n",
    "        #print(len(this_row))\n",
    "        X_aug[r-N_neig] = this_row\n",
    "\n",
    "    return X_aug\n",
    "\n",
    "def augment_features_gradient(X, depth):\n",
    "    d_diff = np.diff(depth).reshape((-1, 1))\n",
    "    d_diff[d_diff==0] = 0.001\n",
    "    X_diff = np.diff(X, axis=0)\n",
    "    X_grad = X_diff / d_diff\n",
    "    X_grad = np.concatenate((X_grad, np.zeros((1, X_grad.shape[1]))))\n",
    "    \n",
    "    return X_grad\n",
    "\n",
    "def augment_features(X, well, depth, N_neig=1):\n",
    "    X_aug = np.zeros((X.shape[0], X.shape[1]*(4*N_neig+1)))\n",
    "    for w in np.unique(well):\n",
    "        w_idx = np.where(well == w)[0]\n",
    "        X_aug_win = augment_features_window(X[w_idx, :], N_neig)\n",
    "        #print(X_aug_win)\n",
    "        #X_aug_grad = augment_features_gradient(X[w_idx, :], depth[w_idx])\n",
    "        #print(X_aug_grad)\n",
    "        X_aug[w_idx, :] = X_aug_win\n",
    "        #X_aug[w_idx, :] = np.concatenate((X_aug_win, X_aug_grad), axis=1)\n",
    "        \n",
    "    return X_aug\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knows(y_pred):\n",
    "    max1 = max(y_pred)\n",
    "    id1 = np.where(y_pred == max1)[0][0]\n",
    "    max2 = 0\n",
    "    for index in range(len(y_pred)):\n",
    "        if ((y_pred[index]>max2) and (index != id1)):\n",
    "            max2 = y_pred[index]\n",
    "            id2 = index\n",
    "    max3 = 0\n",
    "    for index in range(len(y_pred)):\n",
    "        if ((y_pred[index]>max3) and (index != id1) and (index != id2)):\n",
    "            max3 = y_pred[index]\n",
    "            id3 = index\n",
    "#     print(max1, \" \", max2, \" \", max3)\n",
    "#     print(id1, \" \", id2, \" \", id3)\n",
    "    if ((abs(max1 - max2) < 1/6*max2) and  (abs(max2 - max3) > 2*max3)):\n",
    "#         print(y_pred)\n",
    "        return [False, id1, id2]\n",
    "    return [True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start running example to used customized objective function\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import math\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "print('start running example to used customized objective function')\n",
    "\n",
    "params = {'max_depth': 2, 'eta': 0.1, 'silent': 1,\n",
    "          'objective': 'multi:softprob', 'num_class': 2}\n",
    "\n",
    "num_round = 2\n",
    "def my_softmax(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    labels_hot = OneHotEncoder(sparse=False, n_values=2).fit_transform(labels.reshape(-1, 1))\n",
    "    grad = preds - labels_hot\n",
    "    hess = preds * (1.0-preds)\n",
    "\n",
    "    return grad.flatten(), hess.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similar(y_res, y_test):\n",
    "    for index in range(len(y_res)):\n",
    "        if (y_res[index] != y_test[index]):\n",
    "            classes[y_res[index], y_test[index]] += 1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_sum_classes(y_test):\n",
    "    for index in range(len(y_test)):\n",
    "        sum_classes[y_test[index]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similar_percent():\n",
    "    for class1 in range(9):           \n",
    "        for class2 in range(9):\n",
    "            classes[class1, class2] = classes[class1, class2]/sum_classes[class1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-1-368c1357b066>, line 39)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-368c1357b066>\"\u001b[0;36m, line \u001b[0;32m39\u001b[0m\n\u001b[0;31m    dtrain = xgb.DMatrix(X_train_robust_norm, label=y_train)\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "import numpy.random as random\n",
    "test = dict()\n",
    "train = dict()\n",
    "acc = 0\n",
    "wells = set(data['Well Name'])\n",
    "classes = dict()\n",
    "for class1 in range(9):\n",
    "    for class2 in range (9):\n",
    "        classes[class1, class2] = 0\n",
    "sum_classes = dict()\n",
    "for class1 in range(9):\n",
    "    sum_classes[class1] = 0\n",
    "group1 = [0, 8, 6, 5, 4]\n",
    "for well in wells:\n",
    "# well = 'SHRIMPLIN'\n",
    "    print(well)\n",
    "    test[well] = new_data[new_data['Well Name'] == well]\n",
    "    train[well] = new_data[new_data['Well Name'] != well]\n",
    "    X_train = train[well][feature_names].values \n",
    "    y_train = train[well]['Facies'].values \n",
    "    X_test = test[well][feature_names].values \n",
    "    y_test = test[well]['Facies'].values \n",
    "    well_train = train[well]['Well Name'].values\n",
    "    well_test = test[well]['Well Name'].values\n",
    "    depth_train = train[well]['Depth'].values\n",
    "    depth_test = test[well]['Depth'].values    \n",
    "\n",
    "    X_aug_train = augment_features(X_train,well_train,depth_train)\n",
    "    X_aug_test = augment_features(X_test,well_test,depth_test)\n",
    "\n",
    "    robust = preprocessing.RobustScaler(quantile_range=(25.0, 75.0)).fit(X_aug_train)\n",
    "    X_train_robust = robust.transform(X_aug_train)\n",
    "    X_test_robust = robust.transform(X_aug_test)\n",
    "\n",
    "    scaler = StandardScaler().fit(X_train_robust)\n",
    "    X_train_robust_norm = scaler.transform(X_train_robust)\n",
    "    X_test_robust_norm = scaler.transform(X_test_robust)\n",
    "    \n",
    "    for index in range(len(y_train)):\n",
    "        if \n",
    "    dtrain = xgb.DMatrix(X_train_robust_norm, label=y_train)\n",
    "    dtest = xgb.DMatrix(X_test_robust_norm, label=y_test)\n",
    "    watchlist = [(dtest, 'eval'), (dtrain, 'train')]\n",
    "    #     model = xgb.train(params, dtrain, 100)\n",
    "    #     bst = xgb.train(param, dtrain, num_round, watchlist, obj=my_logregobj)\n",
    "    model = xgb.Booster(params, [dtrain])\n",
    "    for _ in range(150):\n",
    "        pred = model.predict(dtrain)\n",
    "        g, h = my_softmax(pred, dtrain)\n",
    "        model.boost(dtrain, g, h)\n",
    "    # Evalute\n",
    "    yhat = model.predict(dtest)\n",
    "    yhat_train = model.predict(dtrain)\n",
    "    yhat_labels = np.argmax(yhat, axis=1)\n",
    "    yhat_labels_train = np.argmax(yhat_train, axis=1)\n",
    "    #     ypred = bst.predict(dtest)\n",
    "    print(len(y_test), \" \", len(yhat_labels))\n",
    "    acc += f1_score(y_test, yhat_labels, average='micro')\n",
    "    print(f1_score(y_test, yhat_labels, average='micro'))\n",
    "    print(\"Score on train \", f1_score(y_train, yhat_labels_train , average='micro'))\n",
    "    if (well != \"Recruit F9\"):\n",
    "        print(\"Score 23 \", score23(yhat_labels, y_test) )\n",
    "        acc_23 += score23(yhat_labels, y_test)\n",
    "        print(\"Score 68 \", score68(yhat_labels, y_test) )\n",
    "        acc_68 += score68(yhat_labels, y_test)\n",
    "#     for index in range(len(y_test)):\n",
    "#         print(y_test[index], yhat_labels[index])\n",
    "    print(\"Outliers test\", number_of_outlier(y_test))\n",
    "    print(\"Outliers res\", number_of_outlier(yhat_labels))\n",
    "    most_similar(yhat_labels, y_test)\n",
    "    find_sum_classes(y_test)\n",
    "print('well, boosting of trees, ', acc/10) \n",
    "print('well, boosting of trees 23, ', acc_23/9) \n",
    "print('well, boosting of trees 23, ', acc_68/9) \n",
    "similar_percent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, 0): 0.0,\n",
       " (0, 1): 0.0,\n",
       " (0, 2): 0.005434782608695652,\n",
       " (0, 3): 0.0,\n",
       " (0, 4): 0.0,\n",
       " (0, 5): 0.03260869565217391,\n",
       " (0, 6): 0.03804347826086957,\n",
       " (0, 7): 0.005434782608695652,\n",
       " (0, 8): 0.2554347826086957,\n",
       " (1, 0): 0.003745318352059925,\n",
       " (1, 1): 0.0,\n",
       " (1, 2): 0.13857677902621723,\n",
       " (1, 3): 0.0299625468164794,\n",
       " (1, 4): 0.0,\n",
       " (1, 5): 0.0,\n",
       " (1, 6): 0.0,\n",
       " (1, 7): 0.0,\n",
       " (1, 8): 0.0,\n",
       " (2, 0): 0.0,\n",
       " (2, 1): 0.15474919957310565,\n",
       " (2, 2): 0.0,\n",
       " (2, 3): 0.2486659551760939,\n",
       " (2, 4): 0.0010672358591248667,\n",
       " (2, 5): 0.0064034151547491995,\n",
       " (2, 6): 0.0,\n",
       " (2, 7): 0.0,\n",
       " (2, 8): 0.004268943436499467,\n",
       " (3, 0): 0.0,\n",
       " (3, 1): 0.04774193548387097,\n",
       " (3, 2): 0.2645161290322581,\n",
       " (3, 3): 0.0,\n",
       " (3, 4): 0.005161290322580645,\n",
       " (3, 5): 0.0064516129032258064,\n",
       " (3, 6): 0.0025806451612903226,\n",
       " (3, 7): 0.0012903225806451613,\n",
       " (3, 8): 0.012903225806451613,\n",
       " (4, 0): 0.0,\n",
       " (4, 1): 0.0,\n",
       " (4, 2): 0.01107011070110701,\n",
       " (4, 3): 0.007380073800738007,\n",
       " (4, 4): 0.0,\n",
       " (4, 5): 0.16605166051660517,\n",
       " (4, 6): 0.2066420664206642,\n",
       " (4, 7): 0.014760147601476014,\n",
       " (4, 8): 0.04797047970479705,\n",
       " (5, 0): 0.0033783783783783786,\n",
       " (5, 1): 0.0,\n",
       " (5, 2): 0.0033783783783783786,\n",
       " (5, 3): 0.02027027027027027,\n",
       " (5, 4): 0.060810810810810814,\n",
       " (5, 5): 0.0,\n",
       " (5, 6): 0.19594594594594594,\n",
       " (5, 7): 0.07094594594594594,\n",
       " (5, 8): 0.0777027027027027,\n",
       " (6, 0): 0.018900343642611683,\n",
       " (6, 1): 0.0,\n",
       " (6, 2): 0.003436426116838488,\n",
       " (6, 3): 0.001718213058419244,\n",
       " (6, 4): 0.12027491408934708,\n",
       " (6, 5): 0.23711340206185566,\n",
       " (6, 6): 0.0,\n",
       " (6, 7): 0.020618556701030927,\n",
       " (6, 8): 0.21305841924398625,\n",
       " (7, 0): 0.028368794326241134,\n",
       " (7, 1): 0.0,\n",
       " (7, 2): 0.0,\n",
       " (7, 3): 0.0,\n",
       " (7, 4): 0.028368794326241134,\n",
       " (7, 5): 0.04964539007092199,\n",
       " (7, 6): 0.11347517730496454,\n",
       " (7, 7): 0.0,\n",
       " (7, 8): 0.20567375886524822,\n",
       " (8, 0): 0.0641399416909621,\n",
       " (8, 1): 0.0,\n",
       " (8, 2): 0.0029154518950437317,\n",
       " (8, 3): 0.011661807580174927,\n",
       " (8, 4): 0.011661807580174927,\n",
       " (8, 5): 0.06851311953352769,\n",
       " (8, 6): 0.19825072886297376,\n",
       " (8, 7): 0.05830903790087463,\n",
       " (8, 8): 0.0}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
