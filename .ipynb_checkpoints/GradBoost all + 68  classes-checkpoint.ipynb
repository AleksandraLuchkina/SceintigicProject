{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('facies_vectors_0.csv')\n",
    "feature_names = ['GR', 'ILD_log10', 'DeltaPHI', 'PHIND', 'PE', 'NM_M', 'RELPOS','GR_diff_up', 'ILD_log10_diff_up', 'DeltaPHI_diff_up', 'PHIND_diff_up', 'PE_diff_up', 'NM_M_diff_up', 'RELPOS_diff_up']\n",
    "feature_names_23 = ['GR_diff_up', 'ILD_log10_diff_up', 'DeltaPHI_diff_up', 'PHIND_diff_up', 'PE_diff_up', 'NM_M_diff_up', 'RELPOS_diff_up','GR_diff_down', 'ILD_log10_diff_down', 'DeltaPHI_diff_down', 'PHIND_diff_down', 'PE_diff_down', 'NM_M_diff_down', 'RELPOS_diff_down','GR', 'ILD_log10', 'DeltaPHI', 'PHIND', 'PE', 'NM_M', 'RELPOS']\n",
    "feature_names_original = ['GR', 'ILD_log10', 'DeltaPHI', 'PHIND', 'PE', 'NM_M', 'RELPOS']\n",
    "data = data.fillna(data['PE'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_diff(row, well):\n",
    "    if len(prev_depth_features[well]) == 0:\n",
    "        prev_depth_features[well] = row.values[4:]\n",
    "        return\n",
    "    diff = row.values[4:] - prev_depth_features[well]\n",
    "    prev_depth_features[well] = row.values[4:]\n",
    "    return diff\n",
    "data_well = dict()\n",
    "data_well_inverse = dict()\n",
    "prev_depth_features = dict()\n",
    "new_data = pd.DataFrame()\n",
    "prev_class= dict()\n",
    "data_save = pd.DataFrame()\n",
    "for well in set(data['Well Name']):\n",
    "    prev_depth_features[well] = []\n",
    "    prev_class[well] = []\n",
    "    data_well[well] = data[data['Well Name'] == well]\n",
    "    data_well[well] = data_well[well].sort_values(by=['Depth'])\n",
    "    data_save = data_well[well].iloc[::-1]\n",
    "    data_well[well]['diff_up'] = data_well[well].apply(lambda row: find_diff(row, well), axis=1)\n",
    "    prev_depth_features[well] = []\n",
    "    prev_class[well] = []\n",
    "\n",
    "    data_well[well] = data_well[well].dropna()\n",
    "    data_well[well]['GR_diff_up'] = data_well[well].apply(lambda row: row['diff_up'][0], axis=1)\n",
    "    data_well[well]['ILD_log10_diff_up'] = data_well[well].apply(lambda row: row['diff_up'][1], axis=1)\n",
    "    data_well[well]['DeltaPHI_diff_up'] = data_well[well].apply(lambda row: row['diff_up'][2], axis=1)\n",
    "    data_well[well]['PHIND_diff_up'] = data_well[well].apply(lambda row: row['diff_up'][3], axis=1)\n",
    "    data_well[well]['PE_diff_up'] = data_well[well].apply(lambda row: row['diff_up'][4], axis=1)\n",
    "    data_well[well]['NM_M_diff_up'] = data_well[well].apply(lambda row: row['diff_up'][5], axis=1)\n",
    "    data_well[well]['RELPOS_diff_up'] = data_well[well].apply(lambda row: row['diff_up'][6], axis=1)\n",
    "\n",
    "    new_data = pd.concat([new_data, data_well[well]])\n",
    "    new_data = new_data.drop(['diff_up'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_diff_all23(row, well):\n",
    "    if len(prev_depth_features_all23[well]) == 0:\n",
    "        prev_depth_features_all23[well] = row.values[4:]\n",
    "        return\n",
    "    diff = row.values[4:] - prev_depth_features_all23[well]\n",
    "    prev_depth_features_all23[well] = row.values[4:]\n",
    "    return diff\n",
    "data_well_all23 = dict()\n",
    "data_well_inverse_all23 = dict()\n",
    "prev_depth_features_all23 = dict()\n",
    "new_data_all23 = pd.DataFrame()\n",
    "prev_class_all23= dict()\n",
    "data_save_all23 = pd.DataFrame()\n",
    "for well in set(data['Well Name']):\n",
    "    prev_depth_features_all23[well] = []\n",
    "    prev_class_all23[well] = []\n",
    "    data_well_all23[well] = data[data['Well Name'] == well]\n",
    "    data_well_all23[well] = data_well_all23[well].sort_values(by=['Depth'])\n",
    "    data_save_all23 = data_well_all23[well].iloc[::-1]\n",
    "    data_well_all23[well]['diff_up'] = data_well_all23[well].apply(lambda row: find_diff_all23(row, well), axis=1)\n",
    "    prev_depth_features_all23[well] = []\n",
    "    prev_class_all23[well] = []\n",
    "    data_save_all23 = data_save_all23.apply(lambda row: find_diff_all23(row, well), axis=1)\n",
    "    data_well_all23[well]['diff_down'] = data_save_all23.iloc[::-1]\n",
    "    data_well_all23[well] = data_well_all23[well].dropna()\n",
    "    data_well_all23[well]['GR_diff_up'] = data_well_all23[well].apply(lambda row: row['diff_up'][0], axis=1)\n",
    "    data_well_all23[well]['ILD_log10_diff_up'] = data_well_all23[well].apply(lambda row: row['diff_up'][1], axis=1)\n",
    "    data_well_all23[well]['DeltaPHI_diff_up'] = data_well_all23[well].apply(lambda row: row['diff_up'][2], axis=1)\n",
    "    data_well_all23[well]['PHIND_diff_up'] = data_well_all23[well].apply(lambda row: row['diff_up'][3], axis=1)\n",
    "    data_well_all23[well]['PE_diff_up'] = data_well_all23[well].apply(lambda row: row['diff_up'][4], axis=1)\n",
    "    data_well_all23[well]['NM_M_diff_up'] = data_well_all23[well].apply(lambda row: row['diff_up'][5], axis=1)\n",
    "    data_well_all23[well]['RELPOS_diff_up'] = data_well_all23[well].apply(lambda row: row['diff_up'][6], axis=1)\n",
    "    data_well_all23[well]['GR_diff_down'] = data_well_all23[well].apply(lambda row: row['diff_down'][0], axis=1)\n",
    "    data_well_all23[well]['ILD_log10_diff_down'] = data_well_all23[well].apply(lambda row: row['diff_down'][1], axis=1)\n",
    "    data_well_all23[well]['DeltaPHI_diff_down'] = data_well_all23[well].apply(lambda row: row['diff_down'][2], axis=1)\n",
    "    data_well_all23[well]['PHIND_diff_down'] = data_well_all23[well].apply(lambda row: row['diff_down'][3], axis=1)\n",
    "    data_well_all23[well]['PE_diff_down'] = data_well_all23[well].apply(lambda row: row['diff_down'][4], axis=1)\n",
    "    data_well_all23[well]['NM_M_diff_down'] = data_well_all23[well].apply(lambda row: row['diff_down'][5], axis=1)\n",
    "    data_well_all23[well]['RELPOS_diff_down'] = data_well_all23[well].apply(lambda row: row['diff_down'][6], axis=1)\n",
    "    data_well_all23[well] = data_well_all23[well].drop(['diff_up'], axis=1)\n",
    "    data_well_all23[well] = data_well_all23[well].drop(['diff_down'], axis=1)\n",
    "    new_data_all68 = pd.concat([new_data_all23, data_well_all23[well]])\n",
    "#     new_data_all23 = new_data_all23.drop(['diff_up'], axis=1)\n",
    "#     new_data_all23 = new_data_all23.drop(['diff_down'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data_6 = new_data_all23[new_data_all23['Facies'] == 6]\n",
    "new_data_8 = new_data_all23[new_data_all23['Facies'] == 8]\n",
    "new_data_68 = pd.concat([new_data_6, new_data_8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_features_window(X, N_neig):\n",
    "    N_row = X.shape[0]\n",
    "    N_feat = X.shape[1]\n",
    "    X = np.vstack((np.zeros((N_neig, N_feat)),np.zeros((N_neig, N_feat)), X, np.zeros((N_neig, N_feat)),np.zeros((N_neig, N_feat))))\n",
    "    X_aug = np.zeros((N_row, N_feat*(4*N_neig+1)))\n",
    "    for r in np.arange(N_row) + N_neig:\n",
    "        this_row = []\n",
    "        for c in np.arange(-N_neig,N_neig+1):\n",
    "            this_row = np.hstack((this_row, X[r+c]))\n",
    "            if c != 0:\n",
    "                this_row = np.hstack((this_row, (X[r] + X[r+c])/2))\n",
    "        #print(len(this_row))\n",
    "        X_aug[r-N_neig] = this_row\n",
    "\n",
    "    return X_aug\n",
    "\n",
    "def augment_features_gradient(X, depth):\n",
    "    d_diff = np.diff(depth).reshape((-1, 1))\n",
    "    d_diff[d_diff==0] = 0.001\n",
    "    X_diff = np.diff(X, axis=0)\n",
    "    X_grad = X_diff / d_diff\n",
    "    X_grad = np.concatenate((X_grad, np.zeros((1, X_grad.shape[1]))))\n",
    "    \n",
    "    return X_grad\n",
    "\n",
    "def augment_features(X, well, depth, N_neig=1):\n",
    "    X_aug = np.zeros((X.shape[0], X.shape[1]*(4*N_neig+1)))\n",
    "    for w in np.unique(well):\n",
    "        w_idx = np.where(well == w)[0]\n",
    "        X_aug_win = augment_features_window(X[w_idx, :], N_neig)\n",
    "        #print(X_aug_win)\n",
    "        #X_aug_grad = augment_features_gradient(X[w_idx, :], depth[w_idx])\n",
    "        #print(X_aug_grad)\n",
    "        X_aug[w_idx, :] = X_aug_win\n",
    "        #X_aug[w_idx, :] = np.concatenate((X_aug_win, X_aug_grad), axis=1)\n",
    "        \n",
    "    return X_aug\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start running example to used customized objective function\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import math\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "print('start running example to used customized objective function')\n",
    "\n",
    "params_23 = {'max_depth': 2, 'eta': 0.1, 'silent': 1,\n",
    "          'objective': 'multi:softprob', 'num_class': 2}\n",
    "params = {'max_depth': 2, 'eta': 0.1, 'silent': 1,\n",
    "          'objective': 'multi:softprob', 'num_class': 9}\n",
    "\n",
    "num_round = 2\n",
    "def my_softmax(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    labels_hot = OneHotEncoder(sparse=False, n_values=9).fit_transform(labels.reshape(-1, 1))\n",
    "    grad = preds - labels_hot\n",
    "    hess = preds * (1.0-preds)\n",
    "\n",
    "    return grad.flatten(), hess.flatten()\n",
    "def my_softmax_23(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    labels_hot = OneHotEncoder(sparse=False, n_values=2).fit_transform(labels.reshape(-1, 1))\n",
    "    grad = preds - labels_hot\n",
    "    hess = preds * (1.0-preds)\n",
    "\n",
    "    return grad.flatten(), hess.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_of_outlier(y_res):\n",
    "    outliers = 0\n",
    "    if y_res[0] != y_res[1]:\n",
    "        outliers += 1\n",
    "    if y_res[-1] != y_res[-2]:\n",
    "        outliers += 1\n",
    "    for index in range(1,len(y_res)-1):\n",
    "        if ((y_res[index] != y_res[index-1]) and (y_res[index] != y_res[index+1])):\n",
    "            outliers += 1\n",
    "    return outliers/len(y_res)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similar(y_res, y_test):\n",
    "    for index in range(len(y_res)):\n",
    "        if (y_res[index] != y_test[index]):\n",
    "            classes[y_res[index], y_test[index]] += 1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score68(y_pred, y_test):\n",
    "    y_pred23 = []\n",
    "    y_test23 = []\n",
    "    for index in range(len(y_test)):\n",
    "        if ((y_test[index] == 2) or (y_test[index] == 3)):\n",
    "            y_test23.append(y_test[index])\n",
    "            y_pred23.append(y_pred[index])\n",
    "    return f1_score(y_test23, y_pred23 , average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def found6(y_pred, y_test):\n",
    "    y_6 = 0\n",
    "    sum_6 = 0\n",
    "    for index in range(len(y_test)):\n",
    "        if (y_test[index] == 2):\n",
    "            sum_6 += 1\n",
    "            if (y_pred[index] == 2):\n",
    "                y_6 += 1\n",
    "    return y_6/sum_6\n",
    "\n",
    "def found8(y_pred, y_test):\n",
    "    y_8 = 0\n",
    "    sum_8 = 0\n",
    "    for index in range(len(y_test)):\n",
    "        if (y_test[index] == 3):\n",
    "            sum_8 += 1\n",
    "            if (y_pred[index] == 3):\n",
    "                y_8 += 1\n",
    "    return y_8/sum_8\n",
    "\n",
    "def falsefound6(y_pred, y_test):\n",
    "    y_6 = 0\n",
    "    sum_6 = 0\n",
    "    for index in range(len(y_test)):\n",
    "        if (y_pred[index] == 2):\n",
    "            sum_6 += 1\n",
    "        if (y_test[index] != 2 and y_pred[index] == 2):\n",
    "            y_6 += 1\n",
    "    return y_6/sum_6\n",
    "\n",
    "def falsefound8(y_pred, y_test):\n",
    "    y_8 = 0\n",
    "    sum_8 = 0\n",
    "    for index in range(len(y_test)):\n",
    "        if (y_pred[index] == 3):\n",
    "            sum_8 += 1\n",
    "        if (y_test[index] != 3 and y_pred[index] == 3):\n",
    "            y_8 += 1\n",
    "    return y_8/sum_8\n",
    "\n",
    "def better(y_pred1, y_pred2, y_test):\n",
    "    bet = 0\n",
    "    for index in range(len(y_test)):\n",
    "        if (y_pred1[index] != y_test[index] and y_pred2[index] == y_test[index]):\n",
    "            bet +=1\n",
    "    return bet\n",
    "\n",
    "def worse(y_pred1, y_pred2, y_test):\n",
    "    wor = 0\n",
    "    for index in range(len(y_test)):\n",
    "        if (y_pred1[index] == y_test[index] and y_pred2[index] != y_test[index]):\n",
    "            wor +=1\n",
    "    return wor\n",
    "\n",
    "def change_sum(y_pred1, y_pred2):\n",
    "    sum_ = 0\n",
    "    for index in range(len(y_pred1)):\n",
    "        if (y_pred1[index] != y_pred2[index]):\n",
    "            sum_ += 1\n",
    "    return sum_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KIMZEY A\n",
      "BEFORE  0.5593607305936074\n",
      "438   438\n",
      "AFTER  0.5091324200913242\n",
      "True detected 2, %  0.8235294117647058\n",
      "False detected 2, %  0.32038834951456313\n",
      "True detected 3, %  0.6216216216216216\n",
      "False detected 3, %  0.28125\n",
      "Better results, id  14\n",
      "Worse results, id  36\n",
      "Change  54\n",
      "Score 68  0.5911949685534591\n",
      "SHANKLE\n",
      "BEFORE  0.5803571428571429\n",
      "448   448\n",
      "AFTER  0.5178571428571429\n",
      "True detected 2, %  0.8295454545454546\n",
      "False detected 2, %  0.6054054054054054\n",
      "True detected 3, %  0.47863247863247865\n",
      "False detected 3, %  0.16417910447761194\n",
      "Better results, id  52\n",
      "Worse results, id  80\n",
      "Change  190\n",
      "Score 68  0.4926829268292683\n",
      "CROSS H CATTLE\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-22f47f2e6a34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0myhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0myhat_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myhat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mboost\u001b[0;34m(self, dtrain, grad, hess)\u001b[0m\n\u001b[1;32m    920\u001b[0m                                                \u001b[0mc_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_float\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    921\u001b[0m                                                \u001b[0mc_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_float\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 922\u001b[0;31m                                                c_bst_ulong(len(grad))))\n\u001b[0m\u001b[1;32m    923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    924\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0meval_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy.random as random\n",
    "import copy\n",
    "from sklearn.cluster import KMeans\n",
    "test = dict()\n",
    "train = dict()\n",
    "test_all68 = dict()\n",
    "train_all68 = dict()\n",
    "acc_68 = 0\n",
    "classes = dict()\n",
    "for class1 in range(9):\n",
    "    for class2 in range (9):\n",
    "        classes[class1, class2] = 0\n",
    "acc = 0\n",
    "wells = set(data['Well Name'])\n",
    "wells_23 = set(new_data_23['Well Name'])\n",
    "change = 0\n",
    "for well in wells:\n",
    "# well = 'SHRIMPLIN'\n",
    "    print(well)\n",
    "    test[well] = new_data[new_data['Well Name'] == well]\n",
    "    train[well] = new_data[new_data['Well Name'] != well]\n",
    "    X_train = train[well][feature_names].values \n",
    "    y_train = train[well]['Facies'].values \n",
    "    X_test = test[well][feature_names].values\n",
    "#     X_test = X_test[0:-1]\n",
    "    y_test = test[well]['Facies'].values \n",
    "#     y_test = y_test[0:-1]\n",
    "    well_train = train[well]['Well Name'].values\n",
    "    well_test = test[well]['Well Name'].values\n",
    "#     well_test = well_test[0:-1]\n",
    "    depth_train = train[well]['Depth'].values\n",
    "    depth_test = test[well]['Depth'].values   \n",
    "#     depth_test = depth_test[0:-1]\n",
    "     \n",
    "    X_aug_train = augment_features(X_train,well_train,depth_train)\n",
    "    X_aug_test = augment_features(X_test,well_test,depth_test)\n",
    "\n",
    "    robust = preprocessing.RobustScaler(quantile_range=(25.0, 75.0)).fit(X_aug_train)\n",
    "    X_train_robust = robust.transform(X_aug_train)\n",
    "    X_test_robust = robust.transform(X_aug_test)\n",
    "\n",
    "    scaler = StandardScaler().fit(X_train_robust)\n",
    "    X_train_robust_norm = scaler.transform(X_train_robust)\n",
    "    X_test_robust_norm = scaler.transform(X_test_robust)\n",
    "    \n",
    "    dtrain = xgb.DMatrix(X_train_robust_norm, label=y_train)\n",
    "    dtest = xgb.DMatrix(X_test_robust_norm, label=y_test)\n",
    "    watchlist = [(dtest, 'eval'), (dtrain, 'train')]\n",
    "    model = xgb.Booster(params, [dtrain])\n",
    "    for _ in range(150):\n",
    "        pred = model.predict(dtrain)\n",
    "        g, h = my_softmax(pred, dtrain)\n",
    "        model.boost(dtrain, g, h)\n",
    "    yhat = model.predict(dtest)\n",
    "    yhat_labels = np.argmax(yhat, axis=1)\n",
    "    print(\"BEFORE \", f1_score(y_test, yhat_labels, average='micro'))\n",
    "    \n",
    "    yhat_labels_prev = copy.deepcopy(yhat_labels)\n",
    "    if (well in wells_23):\n",
    "        test_all68[well] = new_data_all23[new_data_all23['Well Name'] == well]\n",
    "        train_all68[well] = new_data_all23[new_data_all23['Well Name'] != well]\n",
    "        X_train_all68 = train_all68[well][feature_names_23].values \n",
    "        y_train_all68 = train_all68[well]['Facies'].values \n",
    "        X_test_all68 = test_all68[well][feature_names_23].values\n",
    "        y_test_all68 = test_all68[well]['Facies'].values \n",
    "        well_train_all68 = train_all68[well]['Well Name'].values\n",
    "        well_test_all68 = test_all68[well]['Well Name'].values\n",
    "        depth_train_all68 = train_all68[well]['Depth'].values\n",
    "        depth_test_all68 = test_all68[well]['Depth'].values   \n",
    "\n",
    "        X_aug_train_all68 = augment_features(X_train_all68,well_train_all68,depth_train_all68)\n",
    "        X_aug_test_all68 = augment_features(X_test_all68,well_test_all68,depth_test_all68)\n",
    "\n",
    "        robust_68 = preprocessing.RobustScaler(quantile_range=(25.0, 75.0)).fit(X_aug_train_all68)\n",
    "        X_train_robust_all68 = robust_68.transform(X_aug_train_all68)\n",
    "        X_test_robust_all68 = robust_68.transform(X_aug_test_all68)\n",
    "\n",
    "        scaler_68 = StandardScaler().fit(X_train_robust_all68)\n",
    "        X_train_robust_norm_all68 = scaler_68.transform(X_train_robust_all68)\n",
    "        X_test_robust_norm_all68 = scaler_68.transform(X_test_robust_all68)\n",
    "        \n",
    "        indeces_not68 = []\n",
    "        for index in range(len(y_train_all68)):\n",
    "            if ((y_train_all68[index] != 2) and (y_train_all68[index] != 3)):\n",
    "                indeces_not68.append(index)\n",
    "        \n",
    "        X_train_robust_norm_68 = np.delete(X_train_robust_norm_all68, indeces_not68, 0)\n",
    "        y_train_68 = np.delete(y_train_all68, indeces_not68)\n",
    "        \n",
    "        for index in range(len(y_train_68)):\n",
    "            y_train_68[index] = y_train_68[index] - 2\n",
    "            \n",
    "        indeces_not68 = []\n",
    "        for index in range(len(yhat_labels)):\n",
    "            if ((yhat_labels[index] != 2) and (yhat_labels[index] != 3)):\n",
    "                indeces_not68.append(index)\n",
    "        \n",
    "        X_test_robust_norm_68 = np.delete(X_test_robust_norm_all68, indeces_not68, 0)\n",
    "        y_test_68 = np.delete(y_test_all68, indeces_not68)\n",
    "#         yhat_labels_prev = np.delete(yhat_labels, indeces_not68)\n",
    "        \n",
    "#         y_train23 = []\n",
    "#         X_train23 = []\n",
    "#         y_test23 = []\n",
    "#         X_test23 = []\n",
    "        \n",
    "#         indeces_68 = []\n",
    "#         for index in range(len(y_train)):\n",
    "#             if (y_train[index] == 2):\n",
    "#                 y_train23.append(0)\n",
    "#                 X_train23.append(X_train_robust_norm[index])\n",
    "#             if (y_train[index] == 3):\n",
    "#                 y_train23.append(1)\n",
    "#                 X_train23.append(X_train_robust_norm[index])\n",
    "# #             if (y_train[index] == 5):\n",
    "# #                 y_train23.append(2)\n",
    "# #                 X_train23.append(X_train_robust_norm[index])\n",
    "#         for index in range(len(yhat_labels)):\n",
    "#             if (yhat_labels[index] == 2):\n",
    "#                 y_test23.append(0)\n",
    "#                 X_test23.append(X_test_robust_norm[index])\n",
    "#                 indeces_68.append(index)\n",
    "#             if (yhat_labels[index] == 3):\n",
    "#                 y_test23.append(1)\n",
    "#                 X_test23.append(X_test_robust_norm[index])\n",
    "#                 indeces_68.append(index)\n",
    "# #             if (yhat_labels[index] == 5):\n",
    "# #                 y_test23.append(2)\n",
    "# #                 X_test23.append(X_test_robust_norm[index])\n",
    "# #                 indeces_68.append(index)\n",
    "                \n",
    "#         dtrain_68 = xgb.DMatrix(np.array(X_train_robust_norm_68), label=np.array(y_train_68))\n",
    "#         dtest_68 = xgb.DMatrix(np.array(X_test_robust_norm_68), label=np.array(y_test_68))\n",
    "#         watchlist = [(dtest_68, 'eval'), (dtrain_68, 'train')]\n",
    "        \n",
    "#         model_68 = xgb.Booster(params_23, [dtrain_68])\n",
    "#         for _ in range(150):\n",
    "#             pred = model_68.predict(dtrain_68)\n",
    "#             g, h = my_softmax_23(pred, dtrain_68)\n",
    "#             model_68.boost(dtrain_68, g, h)\n",
    "        \n",
    "#         yhat_68 = model_68.predict(dtest_68)\n",
    "#         yhat_labels_68 = np.argmax(yhat_68, axis=1)\n",
    "        \n",
    "        kmeans = KMeans(n_clusters=2, max_iter=500, n_init=10, random_state=0).fit(X_train_robust_norm_68)\n",
    "        yhat_labels_68 = kmeans.predict(X_test_robust_norm_68)\n",
    "        \n",
    "        for index in range(len(yhat_labels_68)):\n",
    "            if (yhat_labels_68[index] == 0):\n",
    "                yhat_labels_68[index] = 2\n",
    "            if (yhat_labels_68[index] == 1):\n",
    "                yhat_labels_68[index] = 3\n",
    "#             if (yhat_labels_68[index] == 2):\n",
    "#                 yhat_labels_68[index] = 5\n",
    "        \n",
    "#         print(y_test_23)\n",
    "#         print(yhat_labels_prev)\n",
    "#         print(\"Acc in before \", f1_score(y_test_68, yhat_labels_prev, average='micro'))\n",
    "#         print(\"Acc in after \", f1_score(y_test_68, yhat_labels_68, average='micro'))\n",
    "\n",
    "        \n",
    "#         print(\"Acc in \", f1_score(y_test_23, yhat_labels_23, average='micro'))\n",
    "        ind = 0\n",
    "        for index in range(len(yhat_labels)):\n",
    "            if index not in indeces_not68:\n",
    "                if ((yhat_labels[index] == 6) and (yhat_labels_68[ind] == 8)):\n",
    "                    change += 1\n",
    "                if ((yhat_labels[index] == 8) and (yhat_labels_68[ind] == 6)):\n",
    "                    change += 1\n",
    "                yhat_labels[index] = yhat_labels_68[ind]\n",
    "                ind  += 1\n",
    "    yhat_train = model.predict(dtrain)\n",
    "    yhat_labels_train = np.argmax(yhat_train, axis=1)\n",
    "    print(len(y_test), \" \", len(yhat_labels))\n",
    "    acc += f1_score(y_test, yhat_labels, average='micro')\n",
    "    print(\"AFTER \", f1_score(y_test, yhat_labels, average='micro'))\n",
    "    if (well != \"Recruit F9\"):\n",
    "        print(\"True detected 2, % \", found6(yhat_labels_prev, y_test))\n",
    "        print(\"False detected 2, % \", falsefound6(yhat_labels_prev, y_test))\n",
    "        print(\"True detected 3, % \", found8(yhat_labels_prev, y_test))\n",
    "        print(\"False detected 3, % \", falsefound8(yhat_labels_prev, y_test))\n",
    "        print(\"Better results, id \", better(yhat_labels_prev, yhat_labels, y_test))\n",
    "        print(\"Worse results, id \", worse(yhat_labels_prev, yhat_labels, y_test))\n",
    "        print(\"Change \", change_sum(yhat_labels_prev, yhat_labels))\n",
    "    if (well != \"Recruit F9\"):\n",
    "        print(\"Score 68 \", score68(yhat_labels, y_test) )\n",
    "        acc_68 += score68(yhat_labels, y_test)\n",
    "#     print(\"Score on train \", f1_score(y_train, yhat_labels_train , average='micro'))\n",
    "#     print(\"Outliers test\", number_of_outlier(y_test))\n",
    "#     print(\"Outliers res\", number_of_outlier(yhat_labels))\n",
    "#     print(\"Change \", change)\n",
    "    most_similar(yhat_labels, y_test)\n",
    "print('well, boosting of trees, ', acc/10)  \n",
    "print('well, boosting of trees 68, ', acc_68/9) \n",
    "print(change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
