{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('facies_vectors_0.csv')\n",
    "feature_names = ['GR', 'ILD_log10', 'DeltaPHI', 'PHIND', 'PE', 'NM_M', 'RELPOS','GR_diff_up', 'ILD_log10_diff_up', 'DeltaPHI_diff_up', 'PHIND_diff_up', 'PE_diff_up', 'NM_M_diff_up', 'RELPOS_diff_up']\n",
    "facies_names = ['SS', 'CSiS', 'FSiS', 'SiSh', 'MS', 'WS', 'D', 'PS', 'BS']\n",
    "facies_colors = ['#F4D03F', '#F5B041','#DC7633','#6E2C00', '#1B4F72','#2E86C1', '#AED6F1', '#A569BD', '#196F3D']\n",
    "data = data.fillna(data['PE'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start running example to used customized objective function\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import math\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "print('start running example to used customized objective function')\n",
    "\n",
    "params = {'max_depth': 2, 'eta': 0.1, 'silent': 1,\n",
    "          'objective': 'multi:softprob', 'num_class': 9, 'learning_rate':0.1}\n",
    "\n",
    "num_round = 2\n",
    "def my_softmax(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    labels = OneHotEncoder(sparse=False, n_values=9).fit_transform(labels.reshape(-1, 1))\n",
    "    grad = preds - labels\n",
    "    hess = preds * (1.0-preds)\n",
    "    dtrain_len = dtrain.num_row()\n",
    "    \n",
    "#     L = [[0]*9]*dtrain.num_row()\n",
    "#     H = [[0]*9]*dtrain.num_row()\n",
    "#     in_ = 0\n",
    "#     for object_ in range(1, dtrain_len-1):\n",
    "#         ind1 = np.where(preds[object_-1] == max(preds[object_-1]))[0][0]\n",
    "#         max1 = max(preds[object_])\n",
    "#         ind = np.where(preds[object_] == max1)[0][0]\n",
    "#         max2 = 0\n",
    "#         for index in range(len(preds[object_])):\n",
    "#             if (preds[object_][index] > max2):\n",
    "#                 ind2 = np.where(preds[object_] == preds[object_][index])[0][0]\n",
    "#                 if (ind2 != ind):\n",
    "#                     max2 = preds[object_][index]\n",
    "# #         ind2 = np.where(preds[object_+1] == max(preds[object_+1]))[0][0]\n",
    "# #         if(ind1 == ind2):\n",
    "#         if (abs(max2 - max1) < 0.02):\n",
    "#             in_ += 1\n",
    "#             for index in range(9):\n",
    "#                 for class_ in range(9):\n",
    "#                     if (class_ != ind1):\n",
    "#                         L[object_][index] = L[object_][index] - preds[object_][class_] * preds[object_][index]\n",
    "#                         H[object_][index] = H[object_][index] + 2 * preds[object_][index] * preds[object_][index] * preds[object_][class_] - preds[object_][index] * preds[object_][class_] \n",
    "#                 H[object_][index] = H[object_][index] - 2 * preds[object_][index] * preds[object_][index] + preds[object_][index]\n",
    "#                 L[object_][index] = L[object_][index] + preds[object_-1][index]\n",
    "#     print(\"grad \", grad[0])\n",
    "#     print(\"L \", L[0])\n",
    "#     grad = grad - 0.001 *np.array(L)\n",
    "#     print(in_, \" \", dtrain_len-2)\n",
    "#     hess = hess - 0.001*np.array(H)\n",
    "    return grad.flatten(), hess.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_of_outlier(y_res):\n",
    "    outliers = 0\n",
    "    if y_res[0] != y_res[1]:\n",
    "        outliers += 1\n",
    "    if y_res[-1] != y_res[-2]:\n",
    "        outliers += 1\n",
    "    for index in range(1,len(y_res)-1):\n",
    "        if ((y_res[index] != y_res[index-1]) and (y_res[index] != y_res[index+1])):\n",
    "            outliers += 1\n",
    "    return outliers/len(y_res)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similar_classes(y_res, y_test):\n",
    "    for class_1 in range(9):\n",
    "        for class_2 in range(class_1 + 1,9):\n",
    "            for index in range(len(y_test)):\n",
    "                if (((y_test[index] == class_1) and (y_res[index] == class_2)) or ((y_test[index] == class_2) and (y_res[index] == class_1))):\n",
    "                    similar_classes[class_1, class_2] += 1                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recount_most_similar_classes():\n",
    "    for class_1 in range(9):\n",
    "        for class_2 in range(class_1 + 1,9):\n",
    "            similar_classes[class_1, class_2] = similar_classes[class_1, class_2] * 2 /(sum_classes[class_1] + sum_classes[class_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_sum_classes(y_res, y_test):\n",
    "    for class_ in range(9):\n",
    "        for index in range(len(y_test)):\n",
    "            if ((y_test[index] == class_) or (y_res[index] == class_)):\n",
    "                sum_classes[class_] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CROSS H CATTLE\n",
      "500   500\n",
      "0.452\n",
      "Outliers test 0.044\n",
      "Outliers res 0.058\n",
      "NEWBY\n",
      "462   462\n",
      "0.5865800865800865\n",
      "Outliers test 0.032467532467532464\n",
      "Outliers res 0.05194805194805195\n",
      "LUKE G U\n",
      "460   460\n",
      "0.6413043478260869\n",
      "Outliers test 0.006521739130434782\n",
      "Outliers res 0.05\n",
      "SHRIMPLIN\n",
      "470   470\n",
      "0.648936170212766\n",
      "Outliers test 0.002127659574468085\n",
      "Outliers res 0.05106382978723404\n",
      "NOLAN\n",
      "414   414\n",
      "0.5410628019323671\n",
      "Outliers test 0.050724637681159424\n",
      "Outliers res 0.06521739130434782\n",
      "KIMZEY A\n",
      "438   438\n",
      "0.5593607305936074\n",
      "Outliers test 0.0319634703196347\n",
      "Outliers res 0.04794520547945205\n",
      "ALEXANDER D\n",
      "465   465\n",
      "0.6365591397849463\n",
      "Outliers test 0.034408602150537634\n",
      "Outliers res 0.043010752688172046\n",
      "SHANKLE\n",
      "448   448\n",
      "0.5803571428571429\n",
      "Outliers test 0.006696428571428571\n",
      "Outliers res 0.08258928571428571\n",
      "CHURCHMAN BIBLE\n",
      "403   403\n",
      "0.5930521091811415\n",
      "Outliers test 0.05707196029776675\n",
      "Outliers res 0.07692307692307693\n",
      "Recruit F9\n",
      "79   79\n",
      "0.7974683544303798\n",
      "Outliers test 0.0\n",
      "Outliers res 0.0759493670886076\n",
      "well, boosting of trees,  0.6036680883398524\n"
     ]
    }
   ],
   "source": [
    "import numpy.random as random\n",
    "test = dict()\n",
    "train = dict()\n",
    "acc = 0\n",
    "wells = set(data['Well Name'])\n",
    "similar_classes = dict()\n",
    "for class_1 in range(9):\n",
    "        for class_2 in range(class_1 + 1,9):\n",
    "            similar_classes[class_1, class_2] = 0\n",
    "sum_classes = dict()\n",
    "for class_ in range(9):\n",
    "        sum_classes[class_] = 0\n",
    "for well in wells:\n",
    "# well = 'SHRIMPLIN'\n",
    "    print(well)\n",
    "    test[well] = new_data[new_data['Well Name'] == well]\n",
    "    train[well] = new_data[new_data['Well Name'] != well]\n",
    "    X_train = train[well][feature_names].values \n",
    "    y_train = train[well]['Facies'].values \n",
    "    X_test = test[well][feature_names].values \n",
    "    y_test = test[well]['Facies'].values \n",
    "\n",
    "    robust = preprocessing.RobustScaler(quantile_range=(25.0, 75.0)).fit(X_train)\n",
    "    X_train_robust = robust.transform(X_train)\n",
    "    X_test_robust = robust.transform(X__test)\n",
    "\n",
    "    scaler = StandardScaler().fit(X_train_robust)\n",
    "    X_train_robust_norm = scaler.transform(X_train_robust)\n",
    "    X_test_robust_norm = scaler.transform(X_test_robust)\n",
    "    \n",
    "    dtrain = xgb.DMatrix(X_train_robust_norm, label=y_train)\n",
    "    dtest = xgb.DMatrix(X_test_robust_norm, label=y_test)\n",
    "    watchlist = [(dtest, 'eval'), (dtrain, 'train')]\n",
    "    #     model = xgb.train(params, dtrain, 100)\n",
    "    #     bst = xgb.train(param, dtrain, num_round, watchlist, obj=my_logregobj)\n",
    "    model = xgb.Booster(params, [dtrain])\n",
    "    for _ in range(150):\n",
    "        pred = model.predict(dtrain)\n",
    "        g, h = my_softmax(pred, dtrain)\n",
    "        model.boost(dtrain, g, h)\n",
    "    # Evalute\n",
    "    yhat = model.predict(dtest)\n",
    "    yhat_labels = np.argmax(yhat, axis=1)\n",
    "    #     ypred = bst.predict(dtest)\n",
    "    print(len(y_test), \" \", len(yhat_labels))\n",
    "    acc += f1_score(y_test, yhat_labels, average='micro')\n",
    "    print(f1_score(y_test, yhat_labels, average='micro'))\n",
    "#     for index in range(len(y_test)):\n",
    "#         print(y_test[index], yhat_labels[index])\n",
    "    most_similar_classes(yhat_labels, y_test)\n",
    "    find_sum_classes(yhat_labels, y_test)\n",
    "#     print(\"BAND 2 \", bandwidth_2(y_test))\n",
    "#     print(\"BAND 3 \", bandwidth_3(y_test))\n",
    "#     print(\"Before 2 test \", before_2(y_test))\n",
    "#     print(\"After 2 test \", after_2(y_test))\n",
    "#     print(\"Before 2 res \", before_2(yhat_labels))\n",
    "#     print(\"After 2 res \", after_2(yhat_labels))\n",
    "    \n",
    "#     print(\"Before 3 test \", before_3(y_test))\n",
    "#     print(\"After 3 test \", after_3(y_test))\n",
    "#     print(\"Before 3 res \", before_3(yhat_labels))\n",
    "#     print(\"After 3 res \", after_3(yhat_labels))\n",
    "    print(\"Outliers test\", number_of_outlier(y_test))\n",
    "    print(\"Outliers res\", number_of_outlier(yhat_labels))\n",
    "print('well, boosting of trees, ', acc/10)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "recount_most_similar_classes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, 1): 0.0035778175313059034,\n",
       " (0, 2): 0.001272264631043257,\n",
       " (0, 3): 0.0,\n",
       " (0, 4): 0.0,\n",
       " (0, 5): 0.020895522388059702,\n",
       " (0, 6): 0.03035413153456998,\n",
       " (0, 7): 0.02237136465324385,\n",
       " (0, 8): 0.1495480690221857,\n",
       " (1, 2): 0.22208663819402075,\n",
       " (1, 3): 0.06656804733727811,\n",
       " (1, 4): 0.0,\n",
       " (1, 5): 0.0,\n",
       " (1, 6): 0.0,\n",
       " (1, 7): 0.0,\n",
       " (1, 8): 0.0,\n",
       " (2, 3): 0.3704016913319239,\n",
       " (2, 4): 0.004651162790697674,\n",
       " (2, 5): 0.008,\n",
       " (2, 6): 0.00176522506619594,\n",
       " (2, 7): 0.0,\n",
       " (2, 8): 0.00522420548541576,\n",
       " (3, 4): 0.00837404047452896,\n",
       " (3, 5): 0.015037593984962405,\n",
       " (3, 6): 0.003031834259727135,\n",
       " (3, 7): 0.0016129032258064516,\n",
       " (3, 8): 0.01791044776119403,\n",
       " (4, 5): 0.15403422982885084,\n",
       " (4, 6): 0.1889055472263868,\n",
       " (4, 7): 0.02689075630252101,\n",
       " (4, 8): 0.03076923076923077,\n",
       " (5, 6): 0.2873900293255132,\n",
       " (5, 7): 0.0896,\n",
       " (5, 8): 0.1003584229390681,\n",
       " (6, 7): 0.049079754601226995,\n",
       " (6, 8): 0.272108843537415,\n",
       " (7, 8): 0.11774744027303755}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
