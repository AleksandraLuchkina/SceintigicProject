{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('facies_vectors_0.csv')\n",
    "feature_names = ['GR', 'ILD_log10', 'DeltaPHI', 'PHIND', 'PE', 'NM_M', 'RELPOS']\n",
    "facies_names = ['SS', 'CSiS', 'FSiS', 'SiSh', 'MS', 'WS', 'D', 'PS', 'BS']\n",
    "facies_colors = ['#F4D03F', '#F5B041','#DC7633','#6E2C00', '#1B4F72','#2E86C1', '#AED6F1', '#A569BD', '#196F3D']\n",
    "data = data.fillna(data['PE'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start running example to used customized objective function\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import math\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "print('start running example to used customized objective function')\n",
    "\n",
    "params = {'max_depth': 2, 'eta': 0.1, 'silent': 1,\n",
    "          'objective': 'multi:softprob', 'num_class': 9, 'learning_rate':0.1}\n",
    "\n",
    "num_round = 2\n",
    "def my_softmax(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    labels = OneHotEncoder(sparse=False, n_values=9).fit_transform(labels.reshape(-1, 1))\n",
    "    grad = preds - labels\n",
    "    hess = preds * (1.0-preds)\n",
    "    dtrain_len = dtrain.num_row()\n",
    "    \n",
    "#     L = [[0]*9]*dtrain.num_row()\n",
    "#     H = [[0]*9]*dtrain.num_row()\n",
    "#     in_ = 0\n",
    "#     for object_ in range(1, dtrain_len-1):\n",
    "#         ind1 = np.where(preds[object_-1] == max(preds[object_-1]))[0][0]\n",
    "#         max1 = max(preds[object_])\n",
    "#         ind = np.where(preds[object_] == max1)[0][0]\n",
    "#         max2 = 0\n",
    "#         for index in range(len(preds[object_])):\n",
    "#             if (preds[object_][index] > max2):\n",
    "#                 ind2 = np.where(preds[object_] == preds[object_][index])[0][0]\n",
    "#                 if (ind2 != ind):\n",
    "#                     max2 = preds[object_][index]\n",
    "# #         ind2 = np.where(preds[object_+1] == max(preds[object_+1]))[0][0]\n",
    "# #         if(ind1 == ind2):\n",
    "#         if (abs(max2 - max1) < 0.02):\n",
    "#             in_ += 1\n",
    "#             for index in range(9):\n",
    "#                 for class_ in range(9):\n",
    "#                     if (class_ != ind1):\n",
    "#                         L[object_][index] = L[object_][index] - preds[object_][class_] * preds[object_][index]\n",
    "#                         H[object_][index] = H[object_][index] + 2 * preds[object_][index] * preds[object_][index] * preds[object_][class_] - preds[object_][index] * preds[object_][class_] \n",
    "#                 H[object_][index] = H[object_][index] - 2 * preds[object_][index] * preds[object_][index] + preds[object_][index]\n",
    "#                 L[object_][index] = L[object_][index] + preds[object_-1][index]\n",
    "#     print(\"grad \", grad[0])\n",
    "#     print(\"L \", L[0])\n",
    "#     grad = grad - 0.001 *np.array(L)\n",
    "#     print(in_, \" \", dtrain_len-2)\n",
    "#     hess = hess - 0.001*np.array(H)\n",
    "    return grad.flatten(), hess.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_of_outlier(y_res):\n",
    "    outliers = 0\n",
    "    if y_res[0] != y_res[1]:\n",
    "        outliers += 1\n",
    "    if y_res[-1] != y_res[-2]:\n",
    "        outliers += 1\n",
    "    for index in range(1,len(y_res)-1):\n",
    "        if ((y_res[index] != y_res[index-1]) and (y_res[index] != y_res[index+1])):\n",
    "            outliers += 1\n",
    "    return outliers/len(y_res)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similar_classes(y_res, y_test):\n",
    "    for class_1 in range(9):\n",
    "        for class_2 in range(class_1 + 1,9):\n",
    "            for index in range(len(y_test)):\n",
    "                if (((y_test[index] == class_1) and (y_res[index] == class_2)) or ((y_test[index] == class_2) and (y_res[index] == class_1))):\n",
    "                    similar_classes[class_1, class_2] += 1                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recount_most_similar_classes():\n",
    "    for class_1 in range(9):\n",
    "        for class_2 in range(class_1 + 1,9):\n",
    "            similar_classes[class_1, class_2] = similar_classes[class_1, class_2] * 2 /(sum_classes[class_1] + sum_classes[class_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_sum_classes(y_res, y_test):\n",
    "    for class_ in range(9):\n",
    "        for index in range(len(y_test)):\n",
    "            if ((y_test[index] == class_) or (y_res[index] == class_)):\n",
    "                sum_classes[class_] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHRIMPLIN\n",
      "471   471\n",
      "0.5668789808917197\n",
      "Outliers test 0.0021231422505307855\n",
      "Outliers res 0.10615711252653928\n",
      "SHANKLE\n",
      "449   449\n",
      "0.5077951002227171\n",
      "Outliers test 0.0066815144766146995\n",
      "Outliers res 0.05790645879732739\n",
      "KIMZEY A\n",
      "439   439\n",
      "0.530751708428246\n",
      "Outliers test 0.03189066059225513\n",
      "Outliers res 0.10022779043280182\n",
      "CROSS H CATTLE\n",
      "501   501\n",
      "0.3972055888223553\n",
      "Outliers test 0.043912175648702596\n",
      "Outliers res 0.0499001996007984\n",
      "NOLAN\n",
      "415   415\n",
      "0.4963855421686747\n",
      "Outliers test 0.05301204819277108\n",
      "Outliers res 0.08433734939759036\n",
      "LUKE G U\n",
      "461   461\n",
      "0.5835140997830802\n",
      "Outliers test 0.006507592190889371\n",
      "Outliers res 0.09327548806941431\n",
      "NEWBY\n",
      "463   463\n",
      "0.4838012958963283\n",
      "Outliers test 0.032397408207343416\n",
      "Outliers res 0.0755939524838013\n",
      "CHURCHMAN BIBLE\n",
      "404   404\n",
      "0.5420792079207921\n",
      "Outliers test 0.05693069306930693\n",
      "Outliers res 0.10643564356435643\n",
      "Recruit F9\n",
      "80   80\n",
      "0.6625\n",
      "Outliers test 0.0\n",
      "Outliers res 0.1125\n",
      "ALEXANDER D\n",
      "466   466\n",
      "0.6223175965665236\n",
      "Outliers test 0.034334763948497854\n",
      "Outliers res 0.06437768240343347\n",
      "well, boosting of trees,  0.5393229120700437\n"
     ]
    }
   ],
   "source": [
    "import numpy.random as random\n",
    "test = dict()\n",
    "train = dict()\n",
    "acc = 0\n",
    "wells = set(data['Well Name'])\n",
    "similar_classes = dict()\n",
    "for class_1 in range(9):\n",
    "        for class_2 in range(class_1 + 1,9):\n",
    "            similar_classes[class_1, class_2] = 0\n",
    "sum_classes = dict()\n",
    "for class_ in range(9):\n",
    "        sum_classes[class_] = 0\n",
    "for well in wells:\n",
    "# well = 'SHRIMPLIN'\n",
    "    print(well)\n",
    "    test[well] = data[data['Well Name'] == well]\n",
    "    train[well] = data[data['Well Name'] != well]\n",
    "    X_train = train[well][feature_names].values \n",
    "    y_train = train[well]['Facies'].values \n",
    "    X_test = test[well][feature_names].values \n",
    "    y_test = test[well]['Facies'].values \n",
    "\n",
    "    robust = preprocessing.RobustScaler(quantile_range=(25.0, 75.0)).fit(X_train)\n",
    "    X_train_robust = robust.transform(X_train)\n",
    "    X_test_robust = robust.transform(X_test)\n",
    "\n",
    "    scaler = StandardScaler().fit(X_train_robust)\n",
    "    X_train_robust_norm = scaler.transform(X_train_robust)\n",
    "    X_test_robust_norm = scaler.transform(X_test_robust)\n",
    "    \n",
    "    dtrain = xgb.DMatrix(X_train_robust_norm, label=y_train)\n",
    "    dtest = xgb.DMatrix(X_test_robust_norm, label=y_test)\n",
    "    watchlist = [(dtest, 'eval'), (dtrain, 'train')]\n",
    "    #     model = xgb.train(params, dtrain, 100)\n",
    "    #     bst = xgb.train(param, dtrain, num_round, watchlist, obj=my_logregobj)\n",
    "    model = xgb.Booster(params, [dtrain])\n",
    "    for _ in range(150):\n",
    "        pred = model.predict(dtrain)\n",
    "        g, h = my_softmax(pred, dtrain)\n",
    "        model.boost(dtrain, g, h)\n",
    "    # Evalute\n",
    "    yhat = model.predict(dtest)\n",
    "    yhat_labels = np.argmax(yhat, axis=1)\n",
    "    #     ypred = bst.predict(dtest)\n",
    "    print(len(y_test), \" \", len(yhat_labels))\n",
    "    acc += f1_score(y_test, yhat_labels, average='micro')\n",
    "    print(f1_score(y_test, yhat_labels, average='micro'))\n",
    "#     for index in range(len(y_test)):\n",
    "#         print(y_test[index], yhat_labels[index])\n",
    "    most_similar_classes(yhat_labels, y_test)\n",
    "    find_sum_classes(yhat_labels, y_test)\n",
    "#     print(\"BAND 2 \", bandwidth_2(y_test))\n",
    "#     print(\"BAND 3 \", bandwidth_3(y_test))\n",
    "#     print(\"Before 2 test \", before_2(y_test))\n",
    "#     print(\"After 2 test \", after_2(y_test))\n",
    "#     print(\"Before 2 res \", before_2(yhat_labels))\n",
    "#     print(\"After 2 res \", after_2(yhat_labels))\n",
    "    \n",
    "#     print(\"Before 3 test \", before_3(y_test))\n",
    "#     print(\"After 3 test \", after_3(y_test))\n",
    "#     print(\"Before 3 res \", before_3(yhat_labels))\n",
    "#     print(\"After 3 res \", after_3(yhat_labels))\n",
    "    print(\"Outliers test\", number_of_outlier(y_test))\n",
    "    print(\"Outliers res\", number_of_outlier(yhat_labels))\n",
    "print('well, boosting of trees, ', acc/10)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "recount_most_similar_classes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, 1): 0.0,\n",
       " (0, 2): 0.0,\n",
       " (0, 3): 0.0,\n",
       " (0, 4): 0.0057553956834532375,\n",
       " (0, 5): 0.02631578947368421,\n",
       " (0, 6): 0.057233704292527825,\n",
       " (0, 7): 0.0482897384305835,\n",
       " (0, 8): 0.1752738654147105,\n",
       " (1, 2): 0.2818181818181818,\n",
       " (1, 3): 0.06069160197600565,\n",
       " (1, 4): 0.0,\n",
       " (1, 5): 0.0,\n",
       " (1, 6): 0.0015128593040847202,\n",
       " (1, 7): 0.0,\n",
       " (1, 8): 0.0,\n",
       " (2, 3): 0.41482078131292793,\n",
       " (2, 4): 0.001095890410958904,\n",
       " (2, 5): 0.007717750826901874,\n",
       " (2, 6): 0.0016750418760469012,\n",
       " (2, 7): 0.0,\n",
       " (2, 8): 0.0008305647840531562,\n",
       " (3, 4): 0.010796221322537112,\n",
       " (3, 5): 0.012236573759347382,\n",
       " (3, 6): 0.00293398533007335,\n",
       " (3, 7): 0.001557632398753894,\n",
       " (3, 8): 0.02711864406779661,\n",
       " (4, 5): 0.13776137761377613,\n",
       " (4, 6): 0.1802451333813987,\n",
       " (4, 7): 0.06389776357827476,\n",
       " (4, 8): 0.052594171997157074,\n",
       " (5, 6): 0.29941860465116277,\n",
       " (5, 7): 0.03902439024390244,\n",
       " (5, 8): 0.08882521489971347,\n",
       " (6, 7): 0.0656013456686291,\n",
       " (6, 8): 0.29035532994923857,\n",
       " (7, 8): 0.13234077750206782}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
