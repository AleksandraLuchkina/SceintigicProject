{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('facies_vectors_0.csv')\n",
    "feature_names = ['GR', 'ILD_log10', 'DeltaPHI', 'PHIND', 'PE', 'NM_M', 'RELPOS','GR_diff_up', 'ILD_log10_diff_up', 'DeltaPHI_diff_up', 'PHIND_diff_up', 'PE_diff_up', 'NM_M_diff_up', 'RELPOS_diff_up']\n",
    "feature_names_23 = ['GR_diff_up', 'ILD_log10_diff_up', 'DeltaPHI_diff_up', 'PHIND_diff_up', 'PE_diff_up', 'NM_M_diff_up', 'RELPOS_diff_up','GR_diff_down', 'ILD_log10_diff_down', 'DeltaPHI_diff_down', 'PHIND_diff_down', 'PE_diff_down', 'NM_M_diff_down', 'RELPOS_diff_down','GR', 'ILD_log10', 'DeltaPHI', 'PHIND', 'PE', 'NM_M', 'RELPOS']\n",
    "feature_names_original = ['GR', 'ILD_log10', 'DeltaPHI', 'PHIND', 'PE', 'NM_M', 'RELPOS']\n",
    "data = data.fillna(data['PE'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_diff(row, well):\n",
    "    if len(prev_depth_features[well]) == 0:\n",
    "        prev_depth_features[well] = row.values[4:]\n",
    "        return\n",
    "    diff = row.values[4:] - prev_depth_features[well]\n",
    "    prev_depth_features[well] = row.values[4:]\n",
    "    return diff\n",
    "data_well = dict()\n",
    "data_well_inverse = dict()\n",
    "prev_depth_features = dict()\n",
    "new_data = pd.DataFrame()\n",
    "prev_class= dict()\n",
    "data_save = pd.DataFrame()\n",
    "for well in set(data['Well Name']):\n",
    "    prev_depth_features[well] = []\n",
    "    prev_class[well] = []\n",
    "    data_well[well] = data[data['Well Name'] == well]\n",
    "    data_well[well] = data_well[well].sort_values(by=['Depth'])\n",
    "    data_save = data_well[well].iloc[::-1]\n",
    "    data_well[well]['diff_up'] = data_well[well].apply(lambda row: find_diff(row, well), axis=1)\n",
    "    prev_depth_features[well] = []\n",
    "    prev_class[well] = []\n",
    "\n",
    "    data_well[well] = data_well[well].dropna()\n",
    "    data_well[well]['GR_diff_up'] = data_well[well].apply(lambda row: row['diff_up'][0], axis=1)\n",
    "    data_well[well]['ILD_log10_diff_up'] = data_well[well].apply(lambda row: row['diff_up'][1], axis=1)\n",
    "    data_well[well]['DeltaPHI_diff_up'] = data_well[well].apply(lambda row: row['diff_up'][2], axis=1)\n",
    "    data_well[well]['PHIND_diff_up'] = data_well[well].apply(lambda row: row['diff_up'][3], axis=1)\n",
    "    data_well[well]['PE_diff_up'] = data_well[well].apply(lambda row: row['diff_up'][4], axis=1)\n",
    "    data_well[well]['NM_M_diff_up'] = data_well[well].apply(lambda row: row['diff_up'][5], axis=1)\n",
    "    data_well[well]['RELPOS_diff_up'] = data_well[well].apply(lambda row: row['diff_up'][6], axis=1)\n",
    "\n",
    "    new_data = pd.concat([new_data, data_well[well]])\n",
    "    new_data = new_data.drop(['diff_up'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_diff_all23(row, well):\n",
    "    if len(prev_depth_features_all23[well]) == 0:\n",
    "        prev_depth_features_all23[well] = row.values[4:]\n",
    "        return\n",
    "    diff = row.values[4:] - prev_depth_features_all23[well]\n",
    "    prev_depth_features_all23[well] = row.values[4:]\n",
    "    return diff\n",
    "data_well_all23 = dict()\n",
    "data_well_inverse_all23 = dict()\n",
    "prev_depth_features_all23 = dict()\n",
    "new_data_all68 = pd.DataFrame()\n",
    "prev_class_all23= dict()\n",
    "data_save_all23 = pd.DataFrame()\n",
    "for well in set(data['Well Name']):\n",
    "    prev_depth_features_all23[well] = []\n",
    "    prev_class_all23[well] = []\n",
    "    data_well_all23[well] = data[data['Well Name'] == well]\n",
    "    data_well_all23[well] = data_well_all23[well].sort_values(by=['Depth'])\n",
    "    data_save_all23 = data_well_all23[well].iloc[::-1]\n",
    "    data_well_all23[well]['diff_up'] = data_well_all23[well].apply(lambda row: find_diff_all23(row, well), axis=1)\n",
    "    prev_depth_features_all23[well] = []\n",
    "    prev_class_all23[well] = []\n",
    "    data_save_all23 = data_save_all23.apply(lambda row: find_diff_all23(row, well), axis=1)\n",
    "    data_well_all23[well]['diff_down'] = data_save_all23.iloc[::-1]\n",
    "    data_well_all23[well] = data_well_all23[well].dropna()\n",
    "    data_well_all23[well]['GR_diff_up'] = data_well_all23[well].apply(lambda row: row['diff_up'][0], axis=1)\n",
    "    data_well_all23[well]['ILD_log10_diff_up'] = data_well_all23[well].apply(lambda row: row['diff_up'][1], axis=1)\n",
    "    data_well_all23[well]['DeltaPHI_diff_up'] = data_well_all23[well].apply(lambda row: row['diff_up'][2], axis=1)\n",
    "    data_well_all23[well]['PHIND_diff_up'] = data_well_all23[well].apply(lambda row: row['diff_up'][3], axis=1)\n",
    "    data_well_all23[well]['PE_diff_up'] = data_well_all23[well].apply(lambda row: row['diff_up'][4], axis=1)\n",
    "    data_well_all23[well]['NM_M_diff_up'] = data_well_all23[well].apply(lambda row: row['diff_up'][5], axis=1)\n",
    "    data_well_all23[well]['RELPOS_diff_up'] = data_well_all23[well].apply(lambda row: row['diff_up'][6], axis=1)\n",
    "    data_well_all23[well]['GR_diff_down'] = data_well_all23[well].apply(lambda row: row['diff_down'][0], axis=1)\n",
    "    data_well_all23[well]['ILD_log10_diff_down'] = data_well_all23[well].apply(lambda row: row['diff_down'][1], axis=1)\n",
    "    data_well_all23[well]['DeltaPHI_diff_down'] = data_well_all23[well].apply(lambda row: row['diff_down'][2], axis=1)\n",
    "    data_well_all23[well]['PHIND_diff_down'] = data_well_all23[well].apply(lambda row: row['diff_down'][3], axis=1)\n",
    "    data_well_all23[well]['PE_diff_down'] = data_well_all23[well].apply(lambda row: row['diff_down'][4], axis=1)\n",
    "    data_well_all23[well]['NM_M_diff_down'] = data_well_all23[well].apply(lambda row: row['diff_down'][5], axis=1)\n",
    "    data_well_all23[well]['RELPOS_diff_down'] = data_well_all23[well].apply(lambda row: row['diff_down'][6], axis=1)\n",
    "    data_well_all23[well] = data_well_all23[well].drop(['diff_up'], axis=1)\n",
    "    data_well_all23[well] = data_well_all23[well].drop(['diff_down'], axis=1)\n",
    "    new_data_all68 = pd.concat([new_data_all68, data_well_all23[well]])\n",
    "#     new_data_all23 = new_data_all23.drop(['diff_up'], axis=1)\n",
    "#     new_data_all23 = new_data_all23.drop(['diff_down'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data_6 = new_data_all68[new_data_all68['Facies'] == 6]\n",
    "new_data_8 = new_data_all68[new_data_all68['Facies'] == 8]\n",
    "new_data_68 = pd.concat([new_data_6, new_data_8])\n",
    "new_data_5 = new_data_all68[new_data_all68['Facies'] == 5]\n",
    "new_data_56 = pd.concat([new_data_5, new_data_6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_features_window(X, N_neig):\n",
    "    N_row = X.shape[0]\n",
    "    N_feat = X.shape[1]\n",
    "    X = np.vstack((np.zeros((N_neig, N_feat)),np.zeros((N_neig, N_feat)), X, np.zeros((N_neig, N_feat)),np.zeros((N_neig, N_feat))))\n",
    "    X_aug = np.zeros((N_row, N_feat*(4*N_neig+1)))\n",
    "    for r in np.arange(N_row) + N_neig:\n",
    "        this_row = []\n",
    "        for c in np.arange(-N_neig,N_neig+1):\n",
    "            this_row = np.hstack((this_row, X[r+c]))\n",
    "            if c != 0:\n",
    "                this_row = np.hstack((this_row, (X[r] + X[r+c])/2))\n",
    "        #print(len(this_row))\n",
    "        X_aug[r-N_neig] = this_row\n",
    "\n",
    "    return X_aug\n",
    "\n",
    "def augment_features_gradient(X, depth):\n",
    "    d_diff = np.diff(depth).reshape((-1, 1))\n",
    "    d_diff[d_diff==0] = 0.001\n",
    "    X_diff = np.diff(X, axis=0)\n",
    "    X_grad = X_diff / d_diff\n",
    "    X_grad = np.concatenate((X_grad, np.zeros((1, X_grad.shape[1]))))\n",
    "    \n",
    "    return X_grad\n",
    "\n",
    "def augment_features(X, well, depth, N_neig=1):\n",
    "    X_aug = np.zeros((X.shape[0], X.shape[1]*(4*N_neig+1)))\n",
    "    for w in np.unique(well):\n",
    "        w_idx = np.where(well == w)[0]\n",
    "        X_aug_win = augment_features_window(X[w_idx, :], N_neig)\n",
    "        #print(X_aug_win)\n",
    "        #X_aug_grad = augment_features_gradient(X[w_idx, :], depth[w_idx])\n",
    "        #print(X_aug_grad)\n",
    "        X_aug[w_idx, :] = X_aug_win\n",
    "        #X_aug[w_idx, :] = np.concatenate((X_aug_win, X_aug_grad), axis=1)\n",
    "        \n",
    "    return X_aug\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start running example to used customized objective function\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import math\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "print('start running example to used customized objective function')\n",
    "\n",
    "params_68 = {'max_depth': 2, 'eta': 0.1, 'silent': 1,\n",
    "          'objective': 'multi:softprob', 'num_class': 2}\n",
    "params = {'max_depth': 2, 'eta': 0.1, 'silent': 1,\n",
    "          'objective': 'multi:softprob', 'num_class': 9}\n",
    "\n",
    "num_round = 2\n",
    "def my_softmax(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    labels_hot = OneHotEncoder(sparse=False, n_values=9).fit_transform(labels.reshape(-1, 1))\n",
    "    grad = preds - labels_hot\n",
    "    hess = preds * (1.0-preds)\n",
    "\n",
    "    return grad.flatten(), hess.flatten()\n",
    "def my_softmax_68(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    labels_hot = OneHotEncoder(sparse=False, n_values=2).fit_transform(labels.reshape(-1, 1))\n",
    "    grad = preds - labels_hot\n",
    "    hess = preds * (1.0-preds)\n",
    "\n",
    "    return grad.flatten(), hess.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_of_outlier(y_res):\n",
    "    outliers = 0\n",
    "    if y_res[0] != y_res[1]:\n",
    "        outliers += 1\n",
    "    if y_res[-1] != y_res[-2]:\n",
    "        outliers += 1\n",
    "    for index in range(1,len(y_res)-1):\n",
    "        if ((y_res[index] != y_res[index-1]) and (y_res[index] != y_res[index+1])):\n",
    "            outliers += 1\n",
    "    return outliers/len(y_res)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similar(y_res, y_test):\n",
    "    for index in range(len(y_res)):\n",
    "        if (y_res[index] != y_test[index]):\n",
    "            classes[y_res[index], y_test[index]] += 1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score68(y_pred, y_test):\n",
    "    y_pred68 = []\n",
    "    y_test68 = []\n",
    "    for index in range(len(y_test)):\n",
    "        if ((y_test[index] == 6) or (y_test[index] == 8)):\n",
    "            y_test68.append(y_test[index])\n",
    "            y_pred68.append(y_pred[index])\n",
    "    return f1_score(y_test68, y_pred68 , average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score56(y_pred, y_test):\n",
    "    y_pred56 = []\n",
    "    y_test56 = []\n",
    "    for index in range(len(y_test)):\n",
    "        if ((y_test[index] == 5) or (y_test[index] == 6)):\n",
    "            y_test56.append(y_test[index])\n",
    "            y_pred56.append(y_pred[index])\n",
    "    return f1_score(y_test56, y_pred56 , average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def found5(y_pred, y_test):\n",
    "    y_5 = 0\n",
    "    sum_5 = 0\n",
    "    for index in range(len(y_test)):\n",
    "        if (y_test[index] == 5):\n",
    "            sum_5 += 1\n",
    "            if (y_pred[index] == 5):\n",
    "                y_5 += 1\n",
    "    return y_5/sum_5\n",
    "\n",
    "def found6(y_pred, y_test):\n",
    "    y_6 = 0\n",
    "    sum_6 = 0\n",
    "    for index in range(len(y_test)):\n",
    "        if (y_test[index] == 6):\n",
    "            sum_6 += 1\n",
    "            if (y_pred[index] == 6):\n",
    "                y_6 += 1\n",
    "    return y_6/sum_6\n",
    "\n",
    "def found8(y_pred, y_test):\n",
    "    y_8 = 0\n",
    "    sum_8 = 0\n",
    "    for index in range(len(y_test)):\n",
    "        if (y_test[index] == 8):\n",
    "            sum_8 += 1\n",
    "            if (y_pred[index] == 8):\n",
    "                y_8 += 1\n",
    "    return y_8/sum_8\n",
    "\n",
    "def falsefound5(y_pred, y_test):\n",
    "    y_5 = 0\n",
    "    sum_5 = 0\n",
    "    for index in range(len(y_test)):\n",
    "        if (y_pred[index] == 5):\n",
    "            sum_5 += 1\n",
    "        if (y_test[index] != 5 and y_pred[index] == 5):\n",
    "            y_5 += 1\n",
    "    return y_5/sum_5\n",
    "\n",
    "def falsefound6(y_pred, y_test):\n",
    "    y_6 = 0\n",
    "    sum_6 = 0\n",
    "    for index in range(len(y_test)):\n",
    "        if (y_pred[index] == 6):\n",
    "            sum_6 += 1\n",
    "        if (y_test[index] != 6 and y_pred[index] == 6):\n",
    "            y_6 += 1\n",
    "    return y_6/sum_6\n",
    "\n",
    "def falsefound8(y_pred, y_test):\n",
    "    y_8 = 0\n",
    "    sum_8 = 0\n",
    "    for index in range(len(y_test)):\n",
    "        if (y_pred[index] == 8):\n",
    "            sum_8 += 1\n",
    "        if (y_test[index] != 8 and y_pred[index] == 8):\n",
    "            y_8 += 1\n",
    "    return y_8/sum_8\n",
    "\n",
    "def better(y_pred1, y_pred2, y_test):\n",
    "    bet = 0\n",
    "    for index in range(len(y_test)):\n",
    "        if (y_pred1[index] != y_test[index] and y_pred2[index] == y_test[index]):\n",
    "            bet +=1\n",
    "    return bet\n",
    "\n",
    "def worse(y_pred1, y_pred2, y_test):\n",
    "    wor = 0\n",
    "    for index in range(len(y_test)):\n",
    "        if (y_pred1[index] == y_test[index] and y_pred2[index] != y_test[index]):\n",
    "            wor +=1\n",
    "    return wor\n",
    "\n",
    "def change_sum(y_pred1, y_pred2):\n",
    "    sum_ = 0\n",
    "    for index in range(len(y_pred1)):\n",
    "        if (y_pred1[index] != y_pred2[index]):\n",
    "            sum_ += 1\n",
    "    return sum_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CROSS H CATTLE\n",
      "BEFORE  0.45090180360721444\n",
      "499   499\n",
      "AFTER 68 0.44889779559118237\n",
      "True detected 6, %  0.6451612903225806\n",
      "False detected 6, %  0.7222222222222222\n",
      "True detected 8, %  0.5970149253731343\n",
      "False detected 8, %  0.3220338983050847\n",
      "Better results, id  3\n",
      "Worse results, id  4\n",
      "Change  7\n",
      "AFTER 56 0.44889779559118237\n",
      "True detected 5, %  0.0\n",
      "False detected 5, %  1.0\n",
      "True detected 6, %  0.6451612903225806\n",
      "False detected 6, %  0.7222222222222222\n",
      "Better results, id  3\n",
      "Worse results, id  4\n",
      "Change  9\n",
      "ALEXANDER D\n",
      "BEFORE  0.6379310344827587\n",
      "464   464\n",
      "AFTER 68 0.6443965517241379\n",
      "True detected 6, %  0.028985507246376812\n",
      "False detected 6, %  0.8\n",
      "True detected 8, %  0.6804123711340206\n",
      "False detected 8, %  0.31958762886597936\n",
      "Better results, id  4\n",
      "Worse results, id  1\n",
      "Change  7\n",
      "AFTER 56 0.6422413793103449\n",
      "True detected 5, %  0.46153846153846156\n",
      "False detected 5, %  0.7735849056603774\n",
      "True detected 6, %  0.028985507246376812\n",
      "False detected 6, %  0.8\n",
      "Better results, id  3\n",
      "Worse results, id  1\n",
      "Change  11\n",
      "SHANKLE\n",
      "BEFORE  0.5816554809843401\n",
      "447   447\n",
      "AFTER 68 0.5816554809843401\n",
      "True detected 6, %  0.704225352112676\n",
      "False detected 6, %  0.21875\n",
      "True detected 8, %  0.8\n",
      "False detected 8, %  0.3333333333333333\n",
      "Better results, id  7\n",
      "Worse results, id  7\n",
      "Change  14\n",
      "AFTER 56 0.5771812080536913\n",
      "True detected 5, %  0.0\n",
      "False detected 5, %  1.0\n",
      "True detected 6, %  0.704225352112676\n",
      "False detected 6, %  0.21875\n",
      "Better results, id  9\n",
      "Worse results, id  11\n",
      "Change  21\n",
      "CHURCHMAN BIBLE\n",
      "BEFORE  0.5920398009950248\n",
      "402   402\n",
      "AFTER 68 0.5870646766169154\n",
      "True detected 6, %  0.6091954022988506\n",
      "False detected 6, %  0.38372093023255816\n",
      "True detected 8, %  0.5733333333333334\n",
      "False detected 8, %  0.39436619718309857\n",
      "Better results, id  5\n",
      "Worse results, id  7\n",
      "Change  15\n",
      "AFTER 56 0.5845771144278606\n",
      "True detected 5, %  0.4482758620689655\n",
      "False detected 5, %  0.75\n",
      "True detected 6, %  0.6091954022988506\n",
      "False detected 6, %  0.38372093023255816\n",
      "Better results, id  11\n",
      "Worse results, id  14\n",
      "Change  34\n",
      "KIMZEY A\n",
      "BEFORE  0.5583524027459954\n",
      "437   437\n",
      "AFTER 68 0.5537757437070938\n",
      "True detected 6, %  0.6274509803921569\n",
      "False detected 6, %  0.7333333333333333\n",
      "True detected 8, %  0.5888888888888889\n",
      "False detected 8, %  0.32051282051282054\n",
      "Better results, id  6\n",
      "Worse results, id  8\n",
      "Change  25\n",
      "AFTER 56 0.5652173913043478\n",
      "True detected 5, %  0.018867924528301886\n",
      "False detected 5, %  0.6666666666666666\n",
      "True detected 6, %  0.6274509803921569\n",
      "False detected 6, %  0.7333333333333333\n",
      "Better results, id  11\n",
      "Worse results, id  8\n",
      "Change  33\n",
      "NOLAN\n",
      "BEFORE  0.5423728813559322\n",
      "413   413\n",
      "AFTER 68 0.549636803874092\n",
      "True detected 6, %  0.43333333333333335\n",
      "False detected 6, %  0.8\n",
      "True detected 8, %  0.49137931034482757\n",
      "False detected 8, %  0.2875\n",
      "Better results, id  4\n",
      "Worse results, id  1\n",
      "Change  10\n",
      "AFTER 56 0.5617433414043583\n",
      "True detected 5, %  0.0851063829787234\n",
      "False detected 5, %  0.75\n",
      "True detected 6, %  0.43333333333333335\n",
      "False detected 6, %  0.8\n",
      "Better results, id  9\n",
      "Worse results, id  1\n",
      "Change  18\n",
      "NEWBY\n",
      "BEFORE  0.5878524945770065\n",
      "461   461\n",
      "AFTER 68 0.5943600867678959\n",
      "True detected 6, %  0.5833333333333334\n",
      "False detected 6, %  0.44554455445544555\n",
      "True detected 8, %  0.7818181818181819\n",
      "False detected 8, %  0.6126126126126126\n",
      "Better results, id  7\n",
      "Worse results, id  4\n",
      "Change  15\n",
      "AFTER 56 0.5835140997830802\n",
      "True detected 5, %  0.03571428571428571\n",
      "False detected 5, %  0.6666666666666666\n",
      "True detected 6, %  0.5833333333333334\n",
      "False detected 6, %  0.44554455445544555\n",
      "Better results, id  6\n",
      "Worse results, id  8\n",
      "Change  20\n",
      "LUKE G U\n",
      "BEFORE  0.6405228758169934\n",
      "459   459\n",
      "AFTER 68 0.6405228758169934\n",
      "True detected 6, %  0.4166666666666667\n",
      "False detected 6, %  0.3269230769230769\n",
      "True detected 8, %  0.726027397260274\n",
      "False detected 8, %  0.4044943820224719\n",
      "Better results, id  7\n",
      "Worse results, id  7\n",
      "Change  17\n",
      "AFTER 56 0.6383442265795207\n",
      "True detected 5, %  0.5\n",
      "False detected 5, %  0.9375\n",
      "True detected 6, %  0.4166666666666667\n",
      "False detected 6, %  0.3269230769230769\n",
      "Better results, id  8\n",
      "Worse results, id  9\n",
      "Change  26\n",
      "Recruit F9\n",
      "BEFORE  0.7948717948717948\n",
      "78   78\n",
      "AFTER 68 0.7948717948717948\n",
      "AFTER 56 0.7948717948717948\n",
      "SHRIMPLIN\n",
      "BEFORE  0.650319829424307\n",
      "469   469\n",
      "AFTER 68 0.6439232409381663\n",
      "True detected 6, %  0.7301587301587301\n",
      "False detected 6, %  0.5\n",
      "True detected 8, %  0.6911764705882353\n",
      "False detected 8, %  0.3561643835616438\n",
      "Better results, id  4\n",
      "Worse results, id  7\n",
      "Change  18\n",
      "AFTER 56 0.6332622601279317\n",
      "True detected 5, %  0.14285714285714285\n",
      "False detected 5, %  0.18181818181818182\n",
      "True detected 6, %  0.7301587301587301\n",
      "False detected 6, %  0.5\n",
      "Better results, id  5\n",
      "Worse results, id  13\n",
      "Change  25\n",
      "well, boosting of trees,  0.6039105050892613\n",
      "well, boosting of trees 68,  0.0\n",
      "210\n"
     ]
    }
   ],
   "source": [
    "import numpy.random as random\n",
    "import copy\n",
    "from sklearn.cluster import KMeans\n",
    "test = dict()\n",
    "train = dict()\n",
    "test_all68 = dict()\n",
    "train_all68 = dict()\n",
    "test_all56 = dict()\n",
    "train_all56 = dict()\n",
    "acc_56 = 0\n",
    "acc_68 = 0\n",
    "classes = dict()\n",
    "for class1 in range(9):\n",
    "    for class2 in range (9):\n",
    "        classes[class1, class2] = 0\n",
    "acc = 0\n",
    "wells = set(data['Well Name'])\n",
    "wells_68 = set(new_data_68['Well Name'])\n",
    "wells_56 = set(new_data_56['Well Name'])\n",
    "change = 0\n",
    "for well in wells:\n",
    "# well = 'SHRIMPLIN'\n",
    "    print(well)\n",
    "    test[well] = new_data[new_data['Well Name'] == well]\n",
    "    train[well] = new_data[new_data['Well Name'] != well]\n",
    "    X_train = train[well][feature_names].values \n",
    "    y_train = train[well]['Facies'].values \n",
    "    X_test = test[well][feature_names].values\n",
    "    X_test = X_test[0:-1]\n",
    "    y_test = test[well]['Facies'].values \n",
    "    y_test = y_test[0:-1]\n",
    "    well_train = train[well]['Well Name'].values\n",
    "    well_test = test[well]['Well Name'].values\n",
    "    well_test = well_test[0:-1]\n",
    "    depth_train = train[well]['Depth'].values\n",
    "    depth_test = test[well]['Depth'].values   \n",
    "    depth_test = depth_test[0:-1]\n",
    "     \n",
    "    X_aug_train = augment_features(X_train,well_train,depth_train)\n",
    "    X_aug_test = augment_features(X_test,well_test,depth_test)\n",
    "\n",
    "    robust = preprocessing.RobustScaler(quantile_range=(25.0, 75.0)).fit(X_aug_train)\n",
    "    X_train_robust = robust.transform(X_aug_train)\n",
    "    X_test_robust = robust.transform(X_aug_test)\n",
    "\n",
    "    scaler = StandardScaler().fit(X_train_robust)\n",
    "    X_train_robust_norm = scaler.transform(X_train_robust)\n",
    "    X_test_robust_norm = scaler.transform(X_test_robust)\n",
    "    \n",
    "    dtrain = xgb.DMatrix(X_train_robust_norm, label=y_train)\n",
    "    dtest = xgb.DMatrix(X_test_robust_norm, label=y_test)\n",
    "    watchlist = [(dtest, 'eval'), (dtrain, 'train')]\n",
    "    model = xgb.Booster(params, [dtrain])\n",
    "    for _ in range(150):\n",
    "        pred = model.predict(dtrain)\n",
    "        g, h = my_softmax(pred, dtrain)\n",
    "        model.boost(dtrain, g, h)\n",
    "    yhat = model.predict(dtest)\n",
    "    yhat_labels = np.argmax(yhat, axis=1)\n",
    "    print(\"BEFORE \", f1_score(y_test, yhat_labels, average='micro'))\n",
    "    \n",
    "    yhat_labels_prev = copy.deepcopy(yhat_labels)\n",
    "                \n",
    "    if (well in wells_68):\n",
    "        test_all68[well] = new_data_all68[new_data_all68['Well Name'] == well]\n",
    "        train_all68[well] = new_data_all68[new_data_all68['Well Name'] != well]\n",
    "        X_train_all68 = train_all68[well][feature_names].values \n",
    "        y_train_all68 = train_all68[well]['Facies'].values \n",
    "        X_test_all68 = test_all68[well][feature_names].values\n",
    "        y_test_all68 = test_all68[well]['Facies'].values \n",
    "        well_train_all68 = train_all68[well]['Well Name'].values\n",
    "        well_test_all68 = test_all68[well]['Well Name'].values\n",
    "        depth_train_all68 = train_all68[well]['Depth'].values\n",
    "        depth_test_all68 = test_all68[well]['Depth'].values   \n",
    "\n",
    "        X_aug_train_all68 = augment_features(X_train_all68,well_train_all68,depth_train_all68)\n",
    "        X_aug_test_all68 = augment_features(X_test_all68,well_test_all68,depth_test_all68)\n",
    "\n",
    "        robust_68 = preprocessing.RobustScaler(quantile_range=(25.0, 75.0)).fit(X_aug_train_all68)\n",
    "        X_train_robust_all68 = robust_68.transform(X_aug_train_all68)\n",
    "        X_test_robust_all68 = robust_68.transform(X_aug_test_all68)\n",
    "\n",
    "        scaler_68 = StandardScaler().fit(X_train_robust_all68)\n",
    "        X_train_robust_norm_all68 = scaler_68.transform(X_train_robust_all68)\n",
    "        X_test_robust_norm_all68 = scaler_68.transform(X_test_robust_all68)\n",
    "        \n",
    "        indeces_not68 = []\n",
    "        for index in range(len(y_train_all68)):\n",
    "            if ((y_train_all68[index] != 6) and (y_train_all68[index] != 8)):\n",
    "                indeces_not68.append(index)\n",
    "        \n",
    "        X_train_robust_norm_68 = np.delete(X_train_robust_norm_all68, indeces_not68, 0)\n",
    "        y_train_68 = np.delete(y_train_all68, indeces_not68)\n",
    "        \n",
    "        for index in range(len(y_train_68)):\n",
    "            if (y_train_68[index] == 6):\n",
    "                y_train_68[index] = 0\n",
    "            if (y_train_68[index] == 8):\n",
    "                y_train_68[index] = 1\n",
    "            \n",
    "        indeces_not68 = []\n",
    "        indeces_68 = []\n",
    "        for index in range(len(yhat_labels)):\n",
    "            if ((yhat_labels[index] != 6) and (yhat_labels[index] != 8)):\n",
    "                indeces_not68.append(index)\n",
    "            else:\n",
    "                indeces_68.append(index)\n",
    "        \n",
    "        X_test_robust_norm_68 = np.delete(X_test_robust_norm_all68, indeces_not68, 0)\n",
    "        y_test_68 = np.delete(y_test_all68, indeces_not68)\n",
    "        \n",
    "        dtrain_68 = xgb.DMatrix(np.array(X_train_robust_norm_68), label=np.array(y_train_68))\n",
    "        dtest_68 = xgb.DMatrix(np.array(X_test_robust_norm_68), label=np.array(y_test_68))\n",
    "        watchlist = [(dtest_68, 'eval'), (dtrain_68, 'train')]\n",
    "        \n",
    "        model_68 = xgb.Booster(params_68, [dtrain_68])\n",
    "        for _ in range(150):\n",
    "            pred = model_68.predict(dtrain_68)\n",
    "            g, h = my_softmax_68(pred, dtrain_68)\n",
    "            model_68.boost(dtrain_68, g, h)\n",
    "        \n",
    "        yhat_68 = model_68.predict(dtest_68)\n",
    "        yhat_labels_68 = np.argmax(yhat_68, axis=1)\n",
    "        \n",
    "        for index in range(len(yhat_labels_68)):\n",
    "            if (yhat_labels_68[index] == 0):\n",
    "                yhat_labels_68[index] = 6\n",
    "            if (yhat_labels_68[index] == 1):\n",
    "                yhat_labels_68[index] = 8\n",
    "\n",
    "#         print(\"Acc in before \", f1_score(y_test_68, yhat_labels_prev, average='micro'))\n",
    "#         print(\"Acc in after \", f1_score(y_test_68, yhat_labels_68, average='micro'))\n",
    "\n",
    "        ind = 0\n",
    "        for index in range(len(yhat_labels)):\n",
    "            if index not in indeces_not68:\n",
    "                if ((yhat_labels[index] == 6) and (yhat_labels_68[ind] == 8)):\n",
    "                    change += 1\n",
    "                if ((yhat_labels[index] == 8) and (yhat_labels_68[ind] == 6)):\n",
    "                    change += 1\n",
    "                yhat_labels[index] = yhat_labels_68[ind]\n",
    "                ind  += 1\n",
    "    yhat_train = model.predict(dtrain)\n",
    "    yhat_labels_train = np.argmax(yhat_train, axis=1)\n",
    "    print(len(y_test), \" \", len(yhat_labels))\n",
    "    acc += f1_score(y_test, yhat_labels, average='micro')\n",
    "    print(\"AFTER 68\", f1_score(y_test, yhat_labels, average='micro'))\n",
    "    if (well != \"Recruit F9\"):\n",
    "        print(\"True detected 6, % \", found6(yhat_labels_prev, y_test))\n",
    "        print(\"False detected 6, % \", falsefound6(yhat_labels_prev, y_test))\n",
    "        print(\"True detected 8, % \", found8(yhat_labels_prev, y_test))\n",
    "        print(\"False detected 8, % \", falsefound8(yhat_labels_prev, y_test))\n",
    "        print(\"Better results, id \", better(yhat_labels_prev, yhat_labels, y_test))\n",
    "        print(\"Worse results, id \", worse(yhat_labels_prev, yhat_labels, y_test))\n",
    "        print(\"Change \", change_sum(yhat_labels_prev, yhat_labels))\n",
    "    if (well in wells_56):\n",
    "        test_all56[well] = new_data_all68[new_data_all68['Well Name'] == well]\n",
    "        train_all56[well] = new_data_all68[new_data_all68['Well Name'] != well]\n",
    "        X_train_all56 = train_all56[well][feature_names].values \n",
    "        y_train_all56 = train_all56[well]['Facies'].values \n",
    "        X_test_all56 = test_all56[well][feature_names].values\n",
    "        y_test_all56 = test_all56[well]['Facies'].values \n",
    "        well_train_all56 = train_all56[well]['Well Name'].values\n",
    "        well_test_all56 = test_all56[well]['Well Name'].values\n",
    "        depth_train_all56 = train_all56[well]['Depth'].values\n",
    "        depth_test_all56 = test_all56[well]['Depth'].values   \n",
    "\n",
    "        X_aug_train_all56 = augment_features(X_train_all56,well_train_all56,depth_train_all56)\n",
    "        X_aug_test_all56 = augment_features(X_test_all56,well_test_all56,depth_test_all56)\n",
    "\n",
    "        robust_56 = preprocessing.RobustScaler(quantile_range=(25.0, 75.0)).fit(X_aug_train_all56)\n",
    "        X_train_robust_all56 = robust_56.transform(X_aug_train_all56)\n",
    "        X_test_robust_all56 = robust_56.transform(X_aug_test_all56)\n",
    "\n",
    "        scaler_56 = StandardScaler().fit(X_train_robust_all56)\n",
    "        X_train_robust_norm_all56 = scaler_56.transform(X_train_robust_all56)\n",
    "        X_test_robust_norm_all56 = scaler_56.transform(X_test_robust_all56)\n",
    "        \n",
    "        indeces_not56 = []\n",
    "        for index in range(len(y_train_all56)):\n",
    "            if ((y_train_all56[index] != 5) and (y_train_all56[index] != 6)):\n",
    "                indeces_not56.append(index)\n",
    "        \n",
    "        X_train_robust_norm_56 = np.delete(X_train_robust_norm_all56, indeces_not56, 0)\n",
    "        y_train_56 = np.delete(y_train_all56, indeces_not56)\n",
    "        \n",
    "        for index in range(len(y_train_56)):\n",
    "            if (y_train_56[index] == 5):\n",
    "                y_train_56[index] = 0\n",
    "            if (y_train_56[index] == 6):\n",
    "                y_train_56[index] = 1\n",
    "            \n",
    "        indeces_not56 = []\n",
    "        for index in range(len(yhat_labels)):\n",
    "            if ((yhat_labels[index] != 5) and (yhat_labels[index] != 6)):\n",
    "                indeces_not56.append(index)\n",
    "        \n",
    "        X_test_robust_norm_56 = np.delete(X_test_robust_norm_all56, indeces_not56, 0)\n",
    "        y_test_56 = np.delete(y_test_all56, indeces_not56)\n",
    "        \n",
    "        dtrain_56 = xgb.DMatrix(np.array(X_train_robust_norm_56), label=np.array(y_train_56))\n",
    "        dtest_56 = xgb.DMatrix(np.array(X_test_robust_norm_56), label=np.array(y_test_56))\n",
    "        watchlist = [(dtest_56, 'eval'), (dtrain_56, 'train')]\n",
    "        \n",
    "        model_56 = xgb.Booster(params_68, [dtrain_56])\n",
    "        for _ in range(150):\n",
    "            pred = model_56.predict(dtrain_56)\n",
    "            g, h = my_softmax_68(pred, dtrain_56)\n",
    "            model_56.boost(dtrain_56, g, h)\n",
    "        \n",
    "        yhat_56 = model_56.predict(dtest_56)\n",
    "        yhat_labels_56 = np.argmax(yhat_56, axis=1)\n",
    "        \n",
    "        for index in range(len(yhat_labels_56)):\n",
    "            if (yhat_labels_56[index] == 0):\n",
    "                yhat_labels_56[index] = 5\n",
    "            if (yhat_labels_56[index] == 1):\n",
    "                yhat_labels_56[index] = 6\n",
    "                \n",
    "        ind = 0\n",
    "        for index in range(len(yhat_labels)):\n",
    "            if index not in indeces_not56:\n",
    "                if ((yhat_labels[index] == 5) and (yhat_labels_56[ind] == 6)):\n",
    "                    change += 1\n",
    "                if ((yhat_labels[index] == 6) and (yhat_labels_56[ind] == 5)):\n",
    "                    change += 1\n",
    "                yhat_labels[index] = yhat_labels_56[ind]\n",
    "                ind  += 1\n",
    "                \n",
    "    print(\"AFTER 56\", f1_score(y_test, yhat_labels, average='micro'))\n",
    "    \n",
    "    if (well in wells_56):\n",
    "        print(\"True detected 5, % \", found5(yhat_labels_prev, y_test))\n",
    "        print(\"False detected 5, % \", falsefound5(yhat_labels_prev, y_test))\n",
    "        print(\"True detected 6, % \", found6(yhat_labels_prev, y_test))\n",
    "        print(\"False detected 6, % \", falsefound6(yhat_labels_prev, y_test))\n",
    "        print(\"Better results, id \", better(yhat_labels_prev, yhat_labels, y_test))\n",
    "        print(\"Worse results, id \", worse(yhat_labels_prev, yhat_labels, y_test))\n",
    "        print(\"Change \", change_sum(yhat_labels_prev, yhat_labels))\n",
    "#     print(\"Score on train \", f1_score(y_train, yhat_labels_train , average='micro'))\n",
    "#     print(\"Outliers test\", number_of_outlier(y_test))\n",
    "#     print(\"Outliers res\", number_of_outlier(yhat_labels))\n",
    "#     print(\"Change \", change)\n",
    "    most_similar(yhat_labels, y_test)\n",
    "print('well, boosting of trees, ', acc/10)  \n",
    "print('well, boosting of trees 68, ', acc_68/9) \n",
    "print(change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
