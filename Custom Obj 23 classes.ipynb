{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('facies_vectors_0.csv')\n",
    "feature_names = ['GR', 'ILD_log10', 'DeltaPHI', 'PHIND', 'PE', 'NM_M', 'RELPOS','GR_diff_up', 'ILD_log10_diff_up', 'DeltaPHI_diff_up', 'PHIND_diff_up', 'PE_diff_up', 'NM_M_diff_up', 'RELPOS_diff_up']\n",
    "feature_names_23 = ['GR_diff_up', 'ILD_log10_diff_up', 'DeltaPHI_diff_up', 'PHIND_diff_up', 'PE_diff_up', 'NM_M_diff_up', 'RELPOS_diff_up','GR_diff_down', 'ILD_log10_diff_down', 'DeltaPHI_diff_down', 'PHIND_diff_down', 'PE_diff_down', 'NM_M_diff_down', 'RELPOS_diff_down','GR', 'ILD_log10', 'DeltaPHI', 'PHIND', 'PE', 'NM_M', 'RELPOS']\n",
    "feature_names_original = ['GR', 'ILD_log10', 'DeltaPHI', 'PHIND', 'PE', 'NM_M', 'RELPOS','GR_diff_up']\n",
    "facies_names = ['SS', 'CSiS', 'FSiS', 'SiSh', 'MS', 'WS', 'D', 'PS', 'BS']\n",
    "facies_colors = ['#F4D03F', '#F5B041','#DC7633','#6E2C00', '#1B4F72','#2E86C1', '#AED6F1', '#A569BD', '#196F3D']\n",
    "data = data.fillna(data['PE'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_diff(row, well):\n",
    "    if len(prev_depth_features[well]) == 0:\n",
    "        prev_depth_features[well] = row.values[4:]\n",
    "        return\n",
    "    diff = row.values[4:] - prev_depth_features[well]\n",
    "    prev_depth_features[well] = row.values[4:]\n",
    "    return diff\n",
    "data_well = dict()\n",
    "data_well_inverse = dict()\n",
    "prev_depth_features = dict()\n",
    "new_data = pd.DataFrame()\n",
    "prev_class= dict()\n",
    "data_save = pd.DataFrame()\n",
    "for well in set(data['Well Name']):\n",
    "    prev_depth_features[well] = []\n",
    "    prev_class[well] = []\n",
    "    data_well[well] = data[data['Well Name'] == well]\n",
    "    data_well[well] = data_well[well].sort_values(by=['Depth'])\n",
    "    data_save = data_well[well].iloc[::-1]\n",
    "    data_well[well]['diff_up'] = data_well[well].apply(lambda row: find_diff(row, well), axis=1)\n",
    "    prev_depth_features[well] = []\n",
    "    prev_class[well] = []\n",
    "\n",
    "    data_well[well] = data_well[well].dropna()\n",
    "    data_well[well]['GR_diff_up'] = data_well[well].apply(lambda row: row['diff_up'][0], axis=1)\n",
    "    data_well[well]['ILD_log10_diff_up'] = data_well[well].apply(lambda row: row['diff_up'][1], axis=1)\n",
    "    data_well[well]['DeltaPHI_diff_up'] = data_well[well].apply(lambda row: row['diff_up'][2], axis=1)\n",
    "    data_well[well]['PHIND_diff_up'] = data_well[well].apply(lambda row: row['diff_up'][3], axis=1)\n",
    "    data_well[well]['PE_diff_up'] = data_well[well].apply(lambda row: row['diff_up'][4], axis=1)\n",
    "    data_well[well]['NM_M_diff_up'] = data_well[well].apply(lambda row: row['diff_up'][5], axis=1)\n",
    "    data_well[well]['RELPOS_diff_up'] = data_well[well].apply(lambda row: row['diff_up'][6], axis=1)\n",
    "\n",
    "    new_data = pd.concat([new_data, data_well[well]])\n",
    "    new_data = new_data.drop(['diff_up'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_diff_all23(row, well):\n",
    "    if len(prev_depth_features_all23[well]) == 0:\n",
    "        prev_depth_features_all23[well] = row.values[4:]\n",
    "        return\n",
    "    diff = row.values[4:] - prev_depth_features_all23[well]\n",
    "    prev_depth_features_all23[well] = row.values[4:]\n",
    "    return diff\n",
    "data_well_all23 = dict()\n",
    "data_well_inverse_all23 = dict()\n",
    "prev_depth_features_all23 = dict()\n",
    "new_data_all23 = pd.DataFrame()\n",
    "prev_class_all23= dict()\n",
    "data_save_all23 = pd.DataFrame()\n",
    "for well in set(data['Well Name']):\n",
    "    prev_depth_features_all23[well] = []\n",
    "    prev_class_all23[well] = []\n",
    "    data_well_all23[well] = data[data['Well Name'] == well]\n",
    "    data_well_all23[well] = data_well_all23[well].sort_values(by=['Depth'])\n",
    "    data_save_all23 = data_well_all23[well].iloc[::-1]\n",
    "    data_well_all23[well]['diff_up'] = data_well_all23[well].apply(lambda row: find_diff_all23(row, well), axis=1)\n",
    "    prev_depth_features_all23[well] = []\n",
    "    prev_class_all23[well] = []\n",
    "    data_save_all23 = data_save_all23.apply(lambda row: find_diff_all23(row, well), axis=1)\n",
    "    data_well_all23[well]['diff_down'] = data_save_all23.iloc[::-1]\n",
    "    data_well_all23[well] = data_well_all23[well].dropna()\n",
    "    data_well_all23[well]['GR_diff_up'] = data_well_all23[well].apply(lambda row: row['diff_up'][0], axis=1)\n",
    "    data_well_all23[well]['ILD_log10_diff_up'] = data_well_all23[well].apply(lambda row: row['diff_up'][1], axis=1)\n",
    "    data_well_all23[well]['DeltaPHI_diff_up'] = data_well_all23[well].apply(lambda row: row['diff_up'][2], axis=1)\n",
    "    data_well_all23[well]['PHIND_diff_up'] = data_well_all23[well].apply(lambda row: row['diff_up'][3], axis=1)\n",
    "    data_well_all23[well]['PE_diff_up'] = data_well_all23[well].apply(lambda row: row['diff_up'][4], axis=1)\n",
    "    data_well_all23[well]['NM_M_diff_up'] = data_well_all23[well].apply(lambda row: row['diff_up'][5], axis=1)\n",
    "    data_well_all23[well]['RELPOS_diff_up'] = data_well_all23[well].apply(lambda row: row['diff_up'][6], axis=1)\n",
    "    data_well_all23[well]['GR_diff_down'] = data_well_all23[well].apply(lambda row: row['diff_down'][0], axis=1)\n",
    "    data_well_all23[well]['ILD_log10_diff_down'] = data_well_all23[well].apply(lambda row: row['diff_down'][1], axis=1)\n",
    "    data_well_all23[well]['DeltaPHI_diff_down'] = data_well_all23[well].apply(lambda row: row['diff_down'][2], axis=1)\n",
    "    data_well_all23[well]['PHIND_diff_down'] = data_well_all23[well].apply(lambda row: row['diff_down'][3], axis=1)\n",
    "    data_well_all23[well]['PE_diff_down'] = data_well_all23[well].apply(lambda row: row['diff_down'][4], axis=1)\n",
    "    data_well_all23[well]['NM_M_diff_down'] = data_well_all23[well].apply(lambda row: row['diff_down'][5], axis=1)\n",
    "    data_well_all23[well]['RELPOS_diff_down'] = data_well_all23[well].apply(lambda row: row['diff_down'][6], axis=1)\n",
    "    data_well_all23[well] = data_well_all23[well].drop(['diff_up'], axis=1)\n",
    "    data_well_all23[well] = data_well_all23[well].drop(['diff_down'], axis=1)\n",
    "    new_data_all23 = pd.concat([new_data_all23, data_well_all23[well]])\n",
    "#     new_data_all23 = new_data_all23.drop(['diff_up'], axis=1)\n",
    "#     new_data_all23 = new_data_all23.drop(['diff_down'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_23(x):\n",
    "    if (x == 2):\n",
    "        return 0\n",
    "    if (x == 3):\n",
    "        return 1\n",
    "    return x\n",
    "new_data_2 = new_data_all23[new_data_all23['Facies'] == 2]\n",
    "new_data_3 = new_data_all23[new_data_all23['Facies'] == 3]\n",
    "new_data_23 = pd.concat([new_data_2, new_data_3])\n",
    "new_data_23['Facies'] = new_data_23.apply(lambda row: change_23(row['Facies']), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_features_window(X, N_neig):\n",
    "    N_row = X.shape[0]\n",
    "    N_feat = X.shape[1]\n",
    "    X = np.vstack((np.zeros((N_neig, N_feat)),np.zeros((N_neig, N_feat)), X, np.zeros((N_neig, N_feat)),np.zeros((N_neig, N_feat))))\n",
    "    X_aug = np.zeros((N_row, N_feat*(4*N_neig+1)))\n",
    "    for r in np.arange(N_row) + N_neig:\n",
    "        this_row = []\n",
    "        for c in np.arange(-N_neig,N_neig+1):\n",
    "            this_row = np.hstack((this_row, X[r+c]))\n",
    "            if c != 0:\n",
    "                this_row = np.hstack((this_row, (X[r] + X[r+c])/2))\n",
    "        #print(len(this_row))\n",
    "        X_aug[r-N_neig] = this_row\n",
    "\n",
    "    return X_aug\n",
    "\n",
    "def augment_features_gradient(X, depth):\n",
    "    d_diff = np.diff(depth).reshape((-1, 1))\n",
    "    d_diff[d_diff==0] = 0.001\n",
    "    X_diff = np.diff(X, axis=0)\n",
    "    X_grad = X_diff / d_diff\n",
    "    X_grad = np.concatenate((X_grad, np.zeros((1, X_grad.shape[1]))))\n",
    "    \n",
    "    return X_grad\n",
    "\n",
    "def augment_features(X, well, depth, N_neig=1):\n",
    "    X_aug = np.zeros((X.shape[0], X.shape[1]*(4*N_neig+1)))\n",
    "    for w in np.unique(well):\n",
    "        w_idx = np.where(well == w)[0]\n",
    "        X_aug_win = augment_features_window(X[w_idx, :], N_neig)\n",
    "        #print(X_aug_win)\n",
    "        #X_aug_grad = augment_features_gradient(X[w_idx, :], depth[w_idx])\n",
    "        #print(X_aug_grad)\n",
    "        X_aug[w_idx, :] = X_aug_win\n",
    "        #X_aug[w_idx, :] = np.concatenate((X_aug_win, X_aug_grad), axis=1)\n",
    "        \n",
    "    return X_aug\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start running example to used customized objective function\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import math\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "print('start running example to used customized objective function')\n",
    "\n",
    "params_23 = {'max_depth': 2, 'eta': 0.1, 'silent': 1,\n",
    "          'objective': 'multi:softprob', 'num_class': 2}\n",
    "params = {'max_depth': 2, 'eta': 0.1, 'silent': 1,\n",
    "          'objective': 'multi:softprob', 'num_class': 9}\n",
    "\n",
    "num_round = 2\n",
    "def my_softmax(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    labels_hot = OneHotEncoder(sparse=False, n_values=9).fit_transform(labels.reshape(-1, 1))\n",
    "    grad = preds - labels_hot\n",
    "    hess = preds * (1.0-preds)\n",
    "\n",
    "    return grad.flatten(), hess.flatten()\n",
    "def my_softmax_23(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    labels_hot = OneHotEncoder(sparse=False, n_values=2).fit_transform(labels.reshape(-1, 1))\n",
    "    grad = preds - labels_hot\n",
    "    hess = preds * (1.0-preds)\n",
    "\n",
    "    return grad.flatten(), hess.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_of_outlier(y_res):\n",
    "    outliers = 0\n",
    "    if y_res[0] != y_res[1]:\n",
    "        outliers += 1\n",
    "    if y_res[-1] != y_res[-2]:\n",
    "        outliers += 1\n",
    "    for index in range(1,len(y_res)-1):\n",
    "        if ((y_res[index] != y_res[index-1]) and (y_res[index] != y_res[index+1])):\n",
    "            outliers += 1\n",
    "    return outliers/len(y_res)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similar(y_res, y_test):\n",
    "    for index in range(len(y_res)):\n",
    "        if (y_res[index] != y_test[index]):\n",
    "            classes[y_res[index], y_test[index]] += 1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DeltaPHI</th>\n",
       "      <th>DeltaPHI_diff_up</th>\n",
       "      <th>Depth</th>\n",
       "      <th>Facies</th>\n",
       "      <th>Formation</th>\n",
       "      <th>GR</th>\n",
       "      <th>GR_diff_up</th>\n",
       "      <th>ILD_log10</th>\n",
       "      <th>ILD_log10_diff_up</th>\n",
       "      <th>NM_M</th>\n",
       "      <th>NM_M_diff_up</th>\n",
       "      <th>PE</th>\n",
       "      <th>PE_diff_up</th>\n",
       "      <th>PHIND</th>\n",
       "      <th>PHIND_diff_up</th>\n",
       "      <th>RELPOS</th>\n",
       "      <th>RELPOS_diff_up</th>\n",
       "      <th>Well Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1383</th>\n",
       "      <td>-1.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3007.0</td>\n",
       "      <td>8</td>\n",
       "      <td>C LM</td>\n",
       "      <td>25.16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.112</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.890</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.030</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>SHANKLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384</th>\n",
       "      <td>-0.4</td>\n",
       "      <td>1.2</td>\n",
       "      <td>3007.5</td>\n",
       "      <td>4</td>\n",
       "      <td>C LM</td>\n",
       "      <td>26.22</td>\n",
       "      <td>1.06</td>\n",
       "      <td>1.092</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>3.400</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.000</td>\n",
       "      <td>SHANKLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1385</th>\n",
       "      <td>1.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3008.0</td>\n",
       "      <td>4</td>\n",
       "      <td>C LM</td>\n",
       "      <td>65.36</td>\n",
       "      <td>39.14</td>\n",
       "      <td>1.026</td>\n",
       "      <td>-0.066</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.715</td>\n",
       "      <td>1.315</td>\n",
       "      <td>0.015</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>SHANKLE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      DeltaPHI  DeltaPHI_diff_up   Depth  Facies Formation     GR  GR_diff_up  \\\n",
       "1383      -1.6               0.0  3007.0       8      C LM  25.16        0.00   \n",
       "1384      -0.4               1.2  3007.5       4      C LM  26.22        1.06   \n",
       "1385       1.6               2.0  3008.0       4      C LM  65.36       39.14   \n",
       "\n",
       "      ILD_log10  ILD_log10_diff_up  NM_M  NM_M_diff_up   PE  PE_diff_up  \\\n",
       "1383      1.112              0.000     2             0  4.8         0.0   \n",
       "1384      1.092             -0.020     2             0  4.5        -0.3   \n",
       "1385      1.026             -0.066     2             0  4.5         0.0   \n",
       "\n",
       "      PHIND  PHIND_diff_up  RELPOS  RELPOS_diff_up Well Name  \n",
       "1383  2.890          0.000   0.030          -0.015   SHANKLE  \n",
       "1384  3.400          0.510   0.030           0.000   SHANKLE  \n",
       "1385  4.715          1.315   0.015          -0.015   SHANKLE  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Facies</th>\n",
       "      <th>Formation</th>\n",
       "      <th>Well Name</th>\n",
       "      <th>Depth</th>\n",
       "      <th>GR</th>\n",
       "      <th>ILD_log10</th>\n",
       "      <th>DeltaPHI</th>\n",
       "      <th>PHIND</th>\n",
       "      <th>PE</th>\n",
       "      <th>NM_M</th>\n",
       "      <th>...</th>\n",
       "      <th>PE_diff_up</th>\n",
       "      <th>NM_M_diff_up</th>\n",
       "      <th>RELPOS_diff_up</th>\n",
       "      <th>GR_diff_down</th>\n",
       "      <th>ILD_log10_diff_down</th>\n",
       "      <th>DeltaPHI_diff_down</th>\n",
       "      <th>PHIND_diff_down</th>\n",
       "      <th>PE_diff_down</th>\n",
       "      <th>NM_M_diff_down</th>\n",
       "      <th>RELPOS_diff_down</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1382</th>\n",
       "      <td>8</td>\n",
       "      <td>C LM</td>\n",
       "      <td>SHANKLE</td>\n",
       "      <td>3006.5</td>\n",
       "      <td>25.16</td>\n",
       "      <td>1.112</td>\n",
       "      <td>-1.6</td>\n",
       "      <td>2.89</td>\n",
       "      <td>4.8</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1383</th>\n",
       "      <td>8</td>\n",
       "      <td>C LM</td>\n",
       "      <td>SHANKLE</td>\n",
       "      <td>3007.0</td>\n",
       "      <td>25.16</td>\n",
       "      <td>1.112</td>\n",
       "      <td>-1.6</td>\n",
       "      <td>2.89</td>\n",
       "      <td>4.8</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>-1.06</td>\n",
       "      <td>0.020</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>-0.510</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384</th>\n",
       "      <td>4</td>\n",
       "      <td>C LM</td>\n",
       "      <td>SHANKLE</td>\n",
       "      <td>3007.5</td>\n",
       "      <td>26.22</td>\n",
       "      <td>1.092</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>3.40</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-39.14</td>\n",
       "      <td>0.066</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-1.315</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Facies Formation Well Name   Depth     GR  ILD_log10  DeltaPHI  PHIND  \\\n",
       "1382       8      C LM   SHANKLE  3006.5  25.16      1.112      -1.6   2.89   \n",
       "1383       8      C LM   SHANKLE  3007.0  25.16      1.112      -1.6   2.89   \n",
       "1384       4      C LM   SHANKLE  3007.5  26.22      1.092      -0.4   3.40   \n",
       "\n",
       "       PE  NM_M        ...         PE_diff_up  NM_M_diff_up  RELPOS_diff_up  \\\n",
       "1382  4.8     2        ...               -0.3             0          -0.015   \n",
       "1383  4.8     2        ...                0.0             0          -0.015   \n",
       "1384  4.5     2        ...               -0.3             0           0.000   \n",
       "\n",
       "      GR_diff_down  ILD_log10_diff_down  DeltaPHI_diff_down  PHIND_diff_down  \\\n",
       "1382          0.00                0.000                 0.0            0.000   \n",
       "1383         -1.06                0.020                -1.2           -0.510   \n",
       "1384        -39.14                0.066                -2.0           -1.315   \n",
       "\n",
       "      PE_diff_down  NM_M_diff_down  RELPOS_diff_down  \n",
       "1382           0.0               0             0.015  \n",
       "1383           0.3               0             0.000  \n",
       "1384           0.0               0             0.015  \n",
       "\n",
       "[3 rows x 25 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data_all23.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOLAN\n",
      "BEFORE  0.5423728813559322\n",
      "[1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 8, 8]\n",
      "Acc in before  0.7447916666666666\n",
      "Acc in after  0.6145833333333334\n",
      "413   413\n",
      "AFTER  0.48184019370460046\n",
      "Score on train  0.8775838926174496\n",
      "Outliers test 0.05084745762711865\n",
      "Outliers res 0.053268765133171914\n",
      "Change  70\n",
      "LUKE G U\n",
      "BEFORE  0.6405228758169934\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 5, 5, 0, 1, 8, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 8, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 5, 8, 6, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 8, 8]\n",
      "Acc in before  0.7544642857142858\n",
      "Acc in after  0.7008928571428571\n",
      "459   459\n",
      "AFTER  0.6143790849673203\n",
      "Score on train  0.8752378363685785\n",
      "Outliers test 0.006535947712418301\n",
      "Outliers res 0.07407407407407407\n",
      "Change  123\n",
      "NEWBY\n",
      "BEFORE  0.5878524945770065\n",
      "[1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 8, 8]\n",
      "Acc in before  0.6818181818181818\n",
      "Acc in after  0.5852272727272727\n",
      "461   461\n",
      "AFTER  0.5509761388286334\n",
      "Score on train  0.8844166440032635\n",
      "Outliers test 0.03036876355748373\n",
      "Outliers res 0.049891540130151846\n",
      "Change  180\n",
      "CHURCHMAN BIBLE\n",
      "BEFORE  0.5920398009950248\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Acc in before  0.6428571428571429\n",
      "Acc in after  0.5267857142857143\n",
      "402   402\n",
      "AFTER  0.5572139303482587\n",
      "Score on train  0.8859743040685225\n",
      "Outliers test 0.05721393034825871\n",
      "Outliers res 0.0945273631840796\n",
      "Change  207\n",
      "SHRIMPLIN\n",
      "BEFORE  0.650319829424307\n",
      "[1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 8, 8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Acc in before  0.7692307692307693\n",
      "Acc in after  0.5641025641025641\n",
      "469   469\n",
      "AFTER  0.5479744136460555\n",
      "Score on train  0.8841646225129461\n",
      "Outliers test 0.0021321961620469083\n",
      "Outliers res 0.05970149253731343\n",
      "Change  281\n",
      "KIMZEY A\n",
      "BEFORE  0.5583524027459954\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Acc in before  0.7125748502994012\n",
      "Acc in after  0.5568862275449101\n",
      "437   437\n",
      "AFTER  0.4874141876430206\n",
      "Score on train  0.8830045933531478\n",
      "Outliers test 0.029748283752860413\n",
      "Outliers res 0.05491990846681922\n",
      "Change  359\n",
      "Recruit F9\n",
      "BEFORE  0.7948717948717948\n",
      "78   78\n",
      "AFTER  0.7948717948717948\n",
      "Score on train  0.8642857142857143\n",
      "Outliers test 0.0\n",
      "Outliers res 0.07692307692307693\n",
      "Change  359\n",
      "ALEXANDER D\n",
      "BEFORE  0.6379310344827587\n",
      "[1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 6, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1]\n",
      "Acc in before  0.8195121951219513\n",
      "Acc in after  0.6195121951219512\n",
      "464   464\n",
      "AFTER  0.5495689655172413\n",
      "Score on train  0.8843222645617855\n",
      "Outliers test 0.034482758620689655\n",
      "Outliers res 0.04525862068965517\n",
      "Change  444\n",
      "CROSS H CATTLE\n",
      "BEFORE  0.45090180360721444\n",
      "[1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]\n",
      "Acc in before  0.47278911564625853\n",
      "Acc in after  0.3469387755102041\n",
      "499   499\n",
      "AFTER  0.4028056112224449\n",
      "Score on train  0.8821104699093157\n",
      "Outliers test 0.04408817635270541\n",
      "Outliers res 0.06212424849699399\n",
      "Change  526\n",
      "SHANKLE\n",
      "BEFORE  0.5816554809843401\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 8, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 4, 0, 0, 0, 0, 0, 0, 1, 4, 8, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 5, 5, 5, 5, 1, 1, 1, 0, 1, 1, 1, 1, 1, 4, 4, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 5, 5, 1, 8, 8, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "Acc in before  0.5158730158730159\n",
      "Acc in after  0.44841269841269843\n",
      "447   447\n",
      "AFTER  0.5413870246085011\n",
      "Score on train  0.8769981034949879\n",
      "Outliers test 0.008948545861297539\n",
      "Outliers res 0.08053691275167785\n",
      "Change  589\n",
      "well, boosting of trees,  0.5528431345357872\n",
      "589\n"
     ]
    }
   ],
   "source": [
    "import numpy.random as random\n",
    "test = dict()\n",
    "train = dict()\n",
    "test_23 = dict()\n",
    "train_23 = dict()\n",
    "classes = dict()\n",
    "for class1 in range(9):\n",
    "    for class2 in range (9):\n",
    "        classes[class1, class2] = 0\n",
    "acc = 0\n",
    "wells = set(data['Well Name'])\n",
    "wells_23 = set(new_data_23['Well Name'])\n",
    "change = 0\n",
    "for well in wells:\n",
    "# well = 'SHRIMPLIN'\n",
    "    print(well)\n",
    "    test[well] = new_data[new_data['Well Name'] == well]\n",
    "    test_23[well] = new_data_all23[new_data_all23['Well Name'] == well]\n",
    "    train[well] = new_data[new_data['Well Name'] != well]\n",
    "    X_train = train[well][feature_names].values \n",
    "    y_train = train[well]['Facies'].values \n",
    "    X_test = test[well][feature_names].values\n",
    "    X_test = X_test[0:-1]\n",
    "    X_test_all_23 = test_23[well][feature_names_23].values\n",
    "    y_test = test[well]['Facies'].values \n",
    "    y_test = y_test[0:-1]\n",
    "    well_train = train[well]['Well Name'].values\n",
    "    well_test = test[well]['Well Name'].values\n",
    "    well_test = well_test[0:-1]\n",
    "    well_test_23 = test_23[well]['Well Name'].values\n",
    "    depth_train = train[well]['Depth'].values\n",
    "    depth_test = test[well]['Depth'].values   \n",
    "    depth_test = depth_test[0:-1]\n",
    "    depth_test_23 = test_23[well]['Depth'].values   \n",
    "\n",
    "    X_aug_train = augment_features(X_train,well_train,depth_train)\n",
    "    X_aug_test = augment_features(X_test,well_test,depth_test)\n",
    "    X_aug_test_all_23 = augment_features(X_test_all_23, well_test_23, depth_test_23)\n",
    "\n",
    "    robust = preprocessing.RobustScaler(quantile_range=(25.0, 75.0)).fit(X_aug_train)\n",
    "    X_train_robust = robust.transform(X_aug_train)\n",
    "    X_test_robust = robust.transform(X_aug_test)\n",
    "    \n",
    "    robust = preprocessing.RobustScaler(quantile_range=(25.0, 75.0)).fit(X_aug_test_all_23)\n",
    "    X_test_robust_all_23 = robust.transform(X_aug_test_all_23)\n",
    "\n",
    "    scaler = StandardScaler().fit(X_train_robust)\n",
    "    X_train_robust_norm = scaler.transform(X_train_robust)\n",
    "    X_test_robust_norm = scaler.transform(X_test_robust)\n",
    "#     print(X_test_robust_norm[1][1:8])\n",
    "    scaler = StandardScaler().fit(X_test_robust_all_23)\n",
    "    X_test_robust_norm_all_23 = scaler.transform(X_test_robust_all_23)\n",
    "#     print(X_test_robust_norm_all_23[1][-8:-1])\n",
    "    \n",
    "    dtrain = xgb.DMatrix(X_train_robust_norm, label=y_train)\n",
    "    dtest = xgb.DMatrix(X_test_robust_norm, label=y_test)\n",
    "    watchlist = [(dtest, 'eval'), (dtrain, 'train')]\n",
    "    model = xgb.Booster(params, [dtrain])\n",
    "    for _ in range(150):\n",
    "        pred = model.predict(dtrain)\n",
    "        g, h = my_softmax(pred, dtrain)\n",
    "        model.boost(dtrain, g, h)\n",
    "    yhat = model.predict(dtest)\n",
    "    yhat_labels = np.argmax(yhat, axis=1)\n",
    "    print(\"BEFORE \", f1_score(y_test, yhat_labels, average='micro'))\n",
    "    if (well in wells_23):\n",
    "        train_23[well] = new_data_23[new_data_23['Well Name'] != well]\n",
    "        X_train_23 = train_23[well][feature_names_23].values \n",
    "        y_train_23 = train_23[well]['Facies'].values \n",
    "        well_train_23 = train_23[well]['Well Name'].values\n",
    "        depth_train_23 = train_23[well]['Depth'].values\n",
    "        \n",
    "        X_aug_train_23 = augment_features(X_train_23,well_train_23,depth_train_23)\n",
    "\n",
    "        robust_23 = preprocessing.RobustScaler(quantile_range=(25.0, 75.0)).fit(X_aug_train_23)\n",
    "        X_train_robust_23 = robust_23.transform(X_aug_train_23)\n",
    "\n",
    "        scaler_23 = StandardScaler().fit(X_train_robust_23)\n",
    "        X_train_robust_norm_23 = scaler_23.transform(X_train_robust_23)\n",
    "        \n",
    "        dtrain_23 = xgb.DMatrix(X_train_robust_norm_23, label=y_train_23)\n",
    "        \n",
    "        print(y_test_23)\n",
    "        X_test_23 = []\n",
    "        y_test_23 = []\n",
    "        indeces = []\n",
    "        yhat_labels_prev = []\n",
    "        for index in range(len(yhat_labels)):\n",
    "            if ((yhat_labels[index] == 2) or (yhat_labels[index] == 3)):\n",
    "                indeces.append(index)\n",
    "                X_test_23.append(X_test_robust_norm_all_23[index])\n",
    "                y_test_23.append(y_test[index])\n",
    "                yhat_labels_prev.append(yhat_labels[index] - 2)\n",
    "        for index in range(len(y_test_23)):\n",
    "            if (y_test_23[index] == 2):\n",
    "                y_test_23[index] = 0\n",
    "            if (y_test_23[index] == 3):\n",
    "                y_test_23[index] = 1\n",
    "        dtest_23 = xgb.DMatrix(X_test_23, label=y_test_23)\n",
    "        watchlist = [(dtest_23, 'eval'), (dtrain_23, 'train')]\n",
    "        model_23 = xgb.Booster(params_23, [dtrain_23])\n",
    "        for _ in range(150):\n",
    "            pred = model_23.predict(dtrain_23)\n",
    "            g, h = my_softmax_23(pred, dtrain_23)\n",
    "            model_23.boost(dtrain_23, g, h)\n",
    "    \n",
    "        yhat_23 = model_23.predict(dtest_23)\n",
    "        yhat_labels_23 = np.argmax(yhat_23, axis=1)\n",
    "        print(\"Acc in before \", f1_score(y_test_23, yhat_labels_prev, average='micro'))\n",
    "        print(\"Acc in after \", f1_score(y_test_23, yhat_labels_23, average='micro'))\n",
    "        for index in range(len(yhat_labels_23)):\n",
    "            if (yhat_labels_23[index] == 0):\n",
    "                yhat_labels_23[index] = 2\n",
    "            if (yhat_labels_23[index] == 1):\n",
    "                yhat_labels_23[index] = 3\n",
    "        ind = 0\n",
    "#         print(\"Acc in \", f1_score(y_test_23, yhat_labels_23, average='micro'))\n",
    "        for index in indeces:\n",
    "            if ((yhat_labels[index] == 2) and (yhat_labels_23[ind] == 3)):\n",
    "                change += 1\n",
    "            if ((yhat_labels[index] == 3) and (yhat_labels_23[ind] == 2)):\n",
    "                change += 1\n",
    "            yhat_labels[index] = yhat_labels_23[ind]\n",
    "            ind  += 1\n",
    "    yhat_train = model.predict(dtrain)\n",
    "    yhat_labels_train = np.argmax(yhat_train, axis=1)\n",
    "    print(len(y_test), \" \", len(yhat_labels))\n",
    "    acc += f1_score(y_test, yhat_labels, average='micro')\n",
    "    print(\"AFTER \", f1_score(y_test, yhat_labels, average='micro'))\n",
    "    print(\"Score on train \", f1_score(y_train, yhat_labels_train , average='micro'))\n",
    "    print(\"Outliers test\", number_of_outlier(y_test))\n",
    "    print(\"Outliers res\", number_of_outlier(yhat_labels))\n",
    "    print(\"Change \", change)\n",
    "    most_similar(yhat_labels, y_test)\n",
    "print('well, boosting of trees, ', acc/10)  \n",
    "print(change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('facies_vectors_0.csv')\n",
    "feature_names = ['GR_diff_up', 'ILD_log10_diff_up', 'DeltaPHI_diff_up', 'PHIND_diff_up', 'PE_diff_up', 'NM_M_diff_up', 'RELPOS_diff_up','GR_diff_down', 'ILD_log10_diff_down', 'DeltaPHI_diff_down', 'PHIND_diff_down', 'PE_diff_down', 'NM_M_diff_down', 'RELPOS_diff_down','GR', 'ILD_log10', 'DeltaPHI', 'PHIND', 'PE', 'NM_M', 'RELPOS']\n",
    "facies_names = ['SS', 'CSiS', 'FSiS', 'SiSh', 'MS', 'WS', 'D', 'PS', 'BS']\n",
    "facies_colors = ['#F4D03F', '#F5B041','#DC7633','#6E2C00', '#1B4F72','#2E86C1', '#AED6F1', '#A569BD', '#196F3D']\n",
    "data = data.fillna(data['PE'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_diff(row, well):\n",
    "    if len(prev_depth_features[well]) == 0:\n",
    "        prev_depth_features[well] = row.values[4:]\n",
    "        return\n",
    "    diff = row.values[4:] - prev_depth_features[well]\n",
    "    prev_depth_features[well] = row.values[4:]\n",
    "    return diff\n",
    "data_well = dict()\n",
    "data_well_inverse = dict()\n",
    "prev_depth_features = dict()\n",
    "new_data = pd.DataFrame()\n",
    "prev_class= dict()\n",
    "data_save = pd.DataFrame()\n",
    "for well in set(data['Well Name']):\n",
    "    prev_depth_features[well] = []\n",
    "    prev_class[well] = []\n",
    "    data_well[well] = data[data['Well Name'] == well]\n",
    "    data_well[well] = data_well[well].sort_values(by=['Depth'])\n",
    "    data_save = data_well[well].iloc[::-1]\n",
    "    data_well[well]['diff_up'] = data_well[well].apply(lambda row: find_diff(row, well), axis=1)\n",
    "    prev_depth_features[well] = []\n",
    "    prev_class[well] = []\n",
    "    data_save = data_save.apply(lambda row: find_diff(row, well), axis=1)\n",
    "    data_well[well]['diff_down'] = data_save.iloc[::-1]\n",
    "    data_well[well] = data_well[well].dropna()\n",
    "    data_well[well]['GR_diff_up'] = data_well[well].apply(lambda row: row['diff_up'][0], axis=1)\n",
    "    data_well[well]['ILD_log10_diff_up'] = data_well[well].apply(lambda row: row['diff_up'][1], axis=1)\n",
    "    data_well[well]['DeltaPHI_diff_up'] = data_well[well].apply(lambda row: row['diff_up'][2], axis=1)\n",
    "    data_well[well]['PHIND_diff_up'] = data_well[well].apply(lambda row: row['diff_up'][3], axis=1)\n",
    "    data_well[well]['PE_diff_up'] = data_well[well].apply(lambda row: row['diff_up'][4], axis=1)\n",
    "    data_well[well]['NM_M_diff_up'] = data_well[well].apply(lambda row: row['diff_up'][5], axis=1)\n",
    "    data_well[well]['RELPOS_diff_up'] = data_well[well].apply(lambda row: row['diff_up'][6], axis=1)\n",
    "    data_well[well]['GR_diff_down'] = data_well[well].apply(lambda row: row['diff_down'][0], axis=1)\n",
    "    data_well[well]['ILD_log10_diff_down'] = data_well[well].apply(lambda row: row['diff_down'][1], axis=1)\n",
    "    data_well[well]['DeltaPHI_diff_down'] = data_well[well].apply(lambda row: row['diff_down'][2], axis=1)\n",
    "    data_well[well]['PHIND_diff_down'] = data_well[well].apply(lambda row: row['diff_down'][3], axis=1)\n",
    "    data_well[well]['PE_diff_down'] = data_well[well].apply(lambda row: row['diff_down'][4], axis=1)\n",
    "    data_well[well]['NM_M_diff_down'] = data_well[well].apply(lambda row: row['diff_down'][5], axis=1)\n",
    "    data_well[well]['RELPOS_diff_down'] = data_well[well].apply(lambda row: row['diff_down'][6], axis=1)\n",
    "    new_data = pd.concat([new_data, data_well[well]])\n",
    "    new_data = new_data.drop(['diff_up'], axis=1)\n",
    "    new_data = new_data.drop(['diff_down'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_23(x):\n",
    "    if (x == 2):\n",
    "        return 0\n",
    "    if (x == 3):\n",
    "        return 1\n",
    "    return x\n",
    "new_data_2 = new_data[new_data['Facies'] == 2]\n",
    "new_data_3 = new_data[new_data['Facies'] == 3]\n",
    "new_data_23 = pd.concat([new_data_2, new_data_3])\n",
    "new_data_23['Facies'] = new_data_23.apply(lambda row: change_23(row['Facies']), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_features_window(X, N_neig):\n",
    "    N_row = X.shape[0]\n",
    "    N_feat = X.shape[1]\n",
    "    X = np.vstack((np.zeros((N_neig, N_feat)),np.zeros((N_neig, N_feat)), X, np.zeros((N_neig, N_feat)),np.zeros((N_neig, N_feat))))\n",
    "    X_aug = np.zeros((N_row, N_feat*(4*N_neig+1)))\n",
    "    for r in np.arange(N_row) + N_neig:\n",
    "        this_row = []\n",
    "        for c in np.arange(-N_neig,N_neig+1):\n",
    "            this_row = np.hstack((this_row, X[r+c]))\n",
    "            if c != 0:\n",
    "                this_row = np.hstack((this_row, (X[r] + X[r+c])/2))\n",
    "        #print(len(this_row))\n",
    "        X_aug[r-N_neig] = this_row\n",
    "\n",
    "    return X_aug\n",
    "\n",
    "def augment_features_gradient(X, depth):\n",
    "    d_diff = np.diff(depth).reshape((-1, 1))\n",
    "    d_diff[d_diff==0] = 0.001\n",
    "    X_diff = np.diff(X, axis=0)\n",
    "    X_grad = X_diff / d_diff\n",
    "    X_grad = np.concatenate((X_grad, np.zeros((1, X_grad.shape[1]))))\n",
    "    \n",
    "    return X_grad\n",
    "\n",
    "def augment_features(X, well, depth, N_neig=1):\n",
    "    X_aug = np.zeros((X.shape[0], X.shape[1]*(4*N_neig+1)))\n",
    "    for w in np.unique(well):\n",
    "        w_idx = np.where(well == w)[0]\n",
    "        X_aug_win = augment_features_window(X[w_idx, :], N_neig)\n",
    "        #print(X_aug_win)\n",
    "        #X_aug_grad = augment_features_gradient(X[w_idx, :], depth[w_idx])\n",
    "        #print(X_aug_grad)\n",
    "        X_aug[w_idx, :] = X_aug_win\n",
    "        #X_aug[w_idx, :] = np.concatenate((X_aug_win, X_aug_grad), axis=1)\n",
    "        \n",
    "    return X_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LUKE G U\n",
      "0.8530612244897959\n",
      "Outliers test 0.0\n",
      "Outliers res 0.04081632653061224\n",
      "NEWBY\n",
      "0.8079096045197741\n",
      "Outliers test 0.0\n",
      "Outliers res 0.022598870056497175\n",
      "CHURCHMAN BIBLE\n",
      "0.839622641509434\n",
      "Outliers test 0.0\n",
      "Outliers res 0.0660377358490566\n",
      "SHRIMPLIN\n",
      "0.8666666666666667\n",
      "Outliers test 0.0\n",
      "Outliers res 0.025\n",
      "KIMZEY A\n",
      "0.8490566037735849\n",
      "Outliers test 0.0\n",
      "Outliers res 0.018867924528301886\n",
      "ALEXANDER D\n",
      "0.8695652173913043\n",
      "Outliers test 0.0\n",
      "Outliers res 0.043478260869565216\n",
      "SHANKLE\n",
      "0.6536585365853659\n",
      "Outliers test 0.0\n",
      "Outliers res 0.07317073170731707\n",
      "CROSS H CATTLE\n",
      "0.8031914893617021\n",
      "Outliers test 0.0\n",
      "Outliers res 0.05319148936170213\n",
      "NOLAN\n",
      "0.8810810810810811\n",
      "Outliers test 0.0\n",
      "Outliers res 0.02702702702702703\n",
      "well, boosting of trees,  0.8248681183754122\n"
     ]
    }
   ],
   "source": [
    "import numpy.random as random\n",
    "test = dict()\n",
    "train = dict()\n",
    "acc = 0\n",
    "wells = set(new_data_23['Well Name'])\n",
    "for well in wells:\n",
    "# well = 'SHRIMPLIN'\n",
    "    print(well)\n",
    "    test[well] = new_data_23[new_data_23['Well Name'] == well]\n",
    "    X_test = test[well][feature_names].values \n",
    "    y_test = test[well]['Facies'].values \n",
    "    well_test = test[well]['Well Name'].values\n",
    "    depth_test = test[well]['Depth'].values    \n",
    "\n",
    "    X_aug_test = augment_features(X_test,well_test,depth_test)\n",
    "\n",
    "    robust = preprocessing.RobustScaler(quantile_range=(25.0, 75.0)).fit(X_aug_test)\n",
    "    X_test_robust = robust.transform(X_aug_test)\n",
    "\n",
    "    scaler = StandardScaler().fit(X_test_robust)\n",
    "    X_test_robust_norm = scaler.transform(X_test_robust)\n",
    "    \n",
    "    dtest = xgb.DMatrix(X_test_robust_norm, label=y_test)\n",
    "    watchlist = [(dtest, 'eval'), (dtrain, 'train')]\n",
    "    yhat = model_23.predict(dtest)\n",
    "    yhat_labels = np.argmax(yhat, axis=1)\n",
    "\n",
    "    acc += f1_score(y_test, yhat_labels, average='micro')\n",
    "    print(f1_score(y_test, yhat_labels, average='micro'))\n",
    "    print(\"Outliers test\", number_of_outlier(y_test))\n",
    "    print(\"Outliers res\", number_of_outlier(yhat_labels))\n",
    "print('well, boosting of trees, ', acc/9)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
